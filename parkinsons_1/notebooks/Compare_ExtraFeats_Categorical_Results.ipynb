{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results from Hyperparameter Tuning For Current UPDRS\n",
    "Using the protein and peptide data as well as the visit month, predict the UPDRS value as either Mild, Moderate, or Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the csv file for xgboost hyperparameter tuning\n",
    "xgb_hyperparams_df = pd.read_csv('../data/processed/xgboost_extrafeats_future_cat_hyperparam_results.csv', index_col=0)\n",
    "lgb_hyperparams_df = pd.read_csv('../data/processed/lgboost_extrafeats_future_cat_hyperparam_results.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.582591</td>\n",
       "      <td>0.534802</td>\n",
       "      <td>0.981408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.657714</td>\n",
       "      <td>0.152731</td>\n",
       "      <td>0.369053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>1.389338</td>\n",
       "      <td>8.496093</td>\n",
       "      <td>0.716661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>7.847890</td>\n",
       "      <td>3.242325</td>\n",
       "      <td>1.426564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>5.143446</td>\n",
       "      <td>1.899508</td>\n",
       "      <td>9.592843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.754802</td>\n",
       "      <td>0.520609</td>\n",
       "      <td>0.672934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   updrs_1   updrs_2   updrs_3\n",
       "colsample_bytree  0.582591  0.534802  0.981408\n",
       "learning_rate     0.657714  0.152731  0.369053\n",
       "max_depth         5.000000  7.000000  4.000000\n",
       "min_child_weight  1.389338  8.496093  0.716661\n",
       "min_split_gain    0.001299  0.000076  0.000254\n",
       "reg_alpha         7.847890  3.242325  1.426564\n",
       "reg_lambda        5.143446  1.899508  9.592843\n",
       "subsample         0.754802  0.520609  0.672934"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_hyperparams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.788955</td>\n",
       "      <td>0.767595</td>\n",
       "      <td>0.864421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.087901</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.530529</td>\n",
       "      <td>0.527746</td>\n",
       "      <td>0.771962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.236442</td>\n",
       "      <td>0.918564</td>\n",
       "      <td>2.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>2.299038</td>\n",
       "      <td>0.273245</td>\n",
       "      <td>4.413904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>1.647466</td>\n",
       "      <td>2.383878</td>\n",
       "      <td>2.901294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.621922</td>\n",
       "      <td>0.730400</td>\n",
       "      <td>0.768483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   updrs_1   updrs_2   updrs_3\n",
       "colsample_bytree  0.788955  0.767595  0.864421\n",
       "gamma             0.087901  0.001295  0.001502\n",
       "learning_rate     0.530529  0.527746  0.771962\n",
       "max_depth         4.000000  1.000000  7.000000\n",
       "min_child_weight  0.236442  0.918564  2.586700\n",
       "reg_alpha         2.299038  0.273245  4.413904\n",
       "reg_lambda        1.647466  2.383878  2.901294\n",
       "subsample         0.621922  0.730400  0.768483"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the protein and updrs data\n",
    "updrs1_df = pd.read_csv('../data/processed/train_updrs_1_cat.csv')\n",
    "updrs2_df = pd.read_csv('../data/processed/train_updrs_2_cat.csv')\n",
    "updrs3_df = pd.read_csv('../data/processed/train_updrs_3_cat.csv')\n",
    "\n",
    "\n",
    "train_data_new_feats = pd.read_csv(\"../data/processed/train_data_new_feats.csv\")\n",
    "\n",
    "updrs1_cols = [\n",
    "        \"visit_id\",\n",
    "        \"patient_id\",\n",
    "        \"visit_month\",\n",
    "        \"updrs_1\",\n",
    "        \"num_prot_pep\",\n",
    "        \"num_prot\",\n",
    "        \"num_pept\",\n",
    "        \"updrs_1_cat\",\n",
    "    ]\n",
    "updrs2_cols = [\n",
    "        \"visit_id\",\n",
    "        \"patient_id\",\n",
    "        \"visit_month\",\n",
    "        \"updrs_2\",\n",
    "        \"num_prot_pep\",\n",
    "        \"num_prot\",\n",
    "        \"num_pept\",\n",
    "        \"updrs_2_cat\",\n",
    "    ]\n",
    "updrs3_cols = [\n",
    "        \"visit_id\",\n",
    "        \"patient_id\",\n",
    "        \"visit_month\",\n",
    "        \"updrs_3\",\n",
    "        \"num_prot_pep\",\n",
    "        \"num_prot\",\n",
    "        \"num_pept\",\n",
    "        \"updrs_3_cat\",\n",
    "    ]\n",
    "\n",
    "new_updrs1_df = updrs1_df[updrs1_cols].merge(\n",
    "        train_data_new_feats, how=\"left\", on=[\"visit_id\", \"patient_id\"]\n",
    "    )\n",
    "new_updrs2_df = updrs2_df[updrs2_cols].merge(\n",
    "        train_data_new_feats, how=\"left\", on=[\"visit_id\", \"patient_id\"]\n",
    "    )\n",
    "new_updrs3_df = updrs3_df[updrs3_cols].merge(\n",
    "        train_data_new_feats, how=\"left\", on=[\"visit_id\", \"patient_id\"]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mild        854\n",
       "moderate    199\n",
       "severe       15\n",
       "Name: updrs_1_cat, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_updrs1_df['updrs_1_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mild        910\n",
       "moderate    158\n",
       "Name: updrs_2_cat, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_updrs2_df['updrs_2_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mild        880\n",
       "moderate    168\n",
       "severe       10\n",
       "Name: updrs_3_cat, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_updrs3_df['updrs_3_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the categorical updrs scores with numerical for mild, moderate and severe\n",
    "## combine the moderate and severe categories since there are very few severe observations\n",
    "new_updrs1_df['updrs_1_cat'] = new_updrs1_df['updrs_1_cat'].map({'mild': 0, 'moderate': 1, 'severe': 1})\n",
    "new_updrs2_df['updrs_2_cat'] = new_updrs2_df['updrs_2_cat'].map({'mild': 0, 'moderate': 1, 'severe': 1})\n",
    "new_updrs3_df['updrs_3_cat'] = new_updrs3_df['updrs_3_cat'].map({'mild': 0, 'moderate': 1, 'severe': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    880\n",
       "1    178\n",
       "Name: updrs_3_cat, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_updrs3_df['updrs_3_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['visit_id', 'patient_id', 'visit_month', 'updrs_3', 'num_prot_pep',\n",
       "       'num_prot', 'num_pept', 'updrs_3_cat', 'kfold', 'O00391',\n",
       "       ...\n",
       "       'Q9UHG2_Q9UKV8', 'Q9UHG2_Q9UNU6', 'Q9UHG2_Q9Y646', 'Q9UHG2_Q9Y6R7',\n",
       "       'Q9UKV8_Q9UNU6', 'Q9UKV8_Q9Y646', 'Q9UKV8_Q9Y6R7', 'Q9UNU6_Q9Y646',\n",
       "       'Q9UNU6_Q9Y6R7', 'Q9Y646_Q9Y6R7'],\n",
       "      dtype='object', length=25887)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_updrs3_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_fold_validation(df, model, target):\n",
    "\n",
    "    updrs_results = dict()\n",
    "    \n",
    "    for fold in range(0, 5):\n",
    "        # get the train and test data for the current fold\n",
    "        train = df[df['kfold'] != fold].reset_index(drop=True)\n",
    "        test = df[df['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "        # get the train and test data for the current fold\n",
    "        drop_cols = ['visit_id', 'patient_id', f'{target}', 'kfold', f'{target}_cat']\n",
    "        X_train = train.drop(columns=drop_cols)\n",
    "        y_train = train[f'{target}_cat']\n",
    "        X_test = test.drop(columns=drop_cols)\n",
    "        y_test = test[f'{target}_cat']\n",
    "\n",
    "        # train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # make predictions\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "        # save the results\n",
    "        updrs_results[f'{target}_fold_{fold}'] = {\n",
    "            'auc_score': roc_auc_score(y_test, preds),\n",
    "            'acc_score': accuracy_score(y_test, preds),\n",
    "            'precision_score': precision_score(y_test, preds),\n",
    "            'recall_score': recall_score(y_test, preds),\n",
    "        }\n",
    "        \n",
    "    mean_auc = np.mean([updrs_results[f'{target}_fold_{fold}']['auc_score'] for fold in range(0, 5)])\n",
    "    mean_acc = np.mean([updrs_results[f'{target}_fold_{fold}']['acc_score'] for fold in range(0, 5)])\n",
    "    mean_precision = np.mean([updrs_results[f'{target}_fold_{fold}']['precision_score'] for fold in range(0, 5)])\n",
    "    mean_recall = np.mean([updrs_results[f'{target}_fold_{fold}']['recall_score'] for fold in range(0, 5)])\n",
    "    \n",
    "    return mean_auc, mean_acc, mean_precision, mean_recall\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xgboost_model(xgb_hyperparams_df, target):\n",
    "    # train the model using the hyperparameters from the hyperparameter tuning\n",
    "    updrs_hp = xgb_hyperparams_df[target].to_dict()\n",
    "    updrs_hp['max_depth'] = int(updrs_hp['max_depth'])\n",
    "    model = XGBClassifier(**updrs_hp)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model function\n",
    "# model = prepare_xgboost_model(xgb_hyperparams_df, 'updrs_1')\n",
    "# model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:13:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:14:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:14:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:15:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:17:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:18:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:18:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:19:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:20:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_results = dict()\n",
    "\n",
    "for updrs, df in zip(['updrs_1', 'updrs_2', 'updrs_3'], [new_updrs1_df, new_updrs2_df, new_updrs3_df]):\n",
    "    model = prepare_xgboost_model(xgb_hyperparams_df, updrs)\n",
    "    auc, acc, prec, recall = cross_fold_validation(df, model, updrs)\n",
    "    xgb_results[updrs] = {\"auc\":auc,\n",
    "                        \"acc\":acc,\n",
    "                        \"prec\":prec,\n",
    "                        \"recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updrs_1': {'auc': 0.5762656608043825,\n",
       "  'acc': 0.8051950331271115,\n",
       "  'prec': 0.520294968189705,\n",
       "  'recall': 0.19348410044062217},\n",
       " 'updrs_2': {'auc': 0.5614549544471271,\n",
       "  'acc': 0.8417884252555833,\n",
       "  'prec': 0.4120663650075415,\n",
       "  'recall': 0.16236754802931272},\n",
       " 'updrs_3': {'auc': 0.5487669466706919,\n",
       "  'acc': 0.8260557084846623,\n",
       "  'prec': 0.4059090909090909,\n",
       "  'recall': 0.13054615871953332}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Classifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lgboost_model(lgb_hyperparams_df, target):\n",
    "    # train the model using the hyperparameters from the hyperparameter tuning\n",
    "    updrs_hp = lgb_hyperparams_df[target].to_dict()\n",
    "    updrs_hp['max_depth'] = int(updrs_hp['max_depth'])\n",
    "    model = LGBMClassifier(**updrs_hp)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.582591</td>\n",
       "      <td>0.534802</td>\n",
       "      <td>0.981408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.657714</td>\n",
       "      <td>0.152731</td>\n",
       "      <td>0.369053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>1.389338</td>\n",
       "      <td>8.496093</td>\n",
       "      <td>0.716661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   updrs_1   updrs_2   updrs_3\n",
       "colsample_bytree  0.582591  0.534802  0.981408\n",
       "learning_rate     0.657714  0.152731  0.369053\n",
       "max_depth         5.000000  7.000000  4.000000\n",
       "min_child_weight  1.389338  8.496093  0.716661\n",
       "min_split_gain    0.001299  0.000076  0.000254"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_hyperparams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_results = dict()\n",
    "\n",
    "for updrs, df in zip(['updrs_1', 'updrs_2', 'updrs_3'], [new_updrs1_df, new_updrs2_df, new_updrs3_df]):\n",
    "    model = prepare_lgboost_model(lgb_hyperparams_df, updrs)\n",
    "    auc, acc, prec, recall = cross_fold_validation(df, model, updrs)\n",
    "    lgb_results[updrs] = {\"auc\":auc,\n",
    "                        \"acc\":acc,\n",
    "                        \"prec\":prec,\n",
    "                        \"recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updrs_1': {'auc': 0.5500545941798992,\n",
       "  'acc': 0.7921021455837829,\n",
       "  'prec': 0.44117647058823534,\n",
       "  'recall': 0.1457450761798588},\n",
       " 'updrs_2': {'auc': 0.5490609023329611,\n",
       "  'acc': 0.8614540827519634,\n",
       "  'prec': 0.7166666666666667,\n",
       "  'recall': 0.10472742127153892},\n",
       " 'updrs_3': {'auc': 0.544034674980207,\n",
       "  'acc': 0.8373815208657398,\n",
       "  'prec': 0.6247619047619047,\n",
       "  'recall': 0.1017794087763128}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = new_updrs1_df[new_updrs1_df['kfold'] != 4].reset_index(drop=True)\n",
    "test_df = new_updrs1_df[new_updrs1_df['kfold'] == 4].reset_index(drop=True)\n",
    "X_train = train_df.drop(columns=['visit_id', 'patient_id', 'updrs_1', 'kfold', 'updrs_1_cat'])\n",
    "y_train = train_df['updrs_1_cat']\n",
    "X_test = test_df.drop(columns=['visit_id', 'patient_id', 'updrs_1', 'kfold', 'updrs_1_cat'])\n",
    "y_test = test_df['updrs_1_cat']\n",
    "\n",
    "model = prepare_lgboost_model(lgb_hyperparams_df, 'updrs_1')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_df['preds'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 0.5825913965503184,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.6577141319875366,\n",
       " 'max_depth': 5,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 1.3893377197890882,\n",
       " 'min_split_gain': 0.0012986100523735,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 7.84789041763128,\n",
       " 'reg_lambda': 5.143445719389354,\n",
       " 'silent': 'warn',\n",
       " 'subsample': 0.7548022099472674,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = prepare_lgboost_model(lgb_hyperparams_df, 'updrs_1')\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204\n",
       "1      9\n",
       "Name: preds, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 25888)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_preds = test_df[test_df['updrs_1_cat'] != test_df['preds']]\n",
    "wrong_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39\n",
       "0     6\n",
       "Name: updrs_1_cat, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_preds['updrs_1_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View XGBoost Results with Forecasting the UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max category for each patient\n",
    "max_df = new_updrs1_df.groupby(['patient_id'])['updrs_1_cat'].max().reset_index()\n",
    "max_df = max_df.rename(columns={'updrs_1_cat': 'updrs_1_max_cat'})\n",
    "# merge the max category with the original dataframe\n",
    "new_updrs1_df = new_updrs1_df.merge(max_df, on=['patient_id'], how='left')\n",
    "# take only the visit months that are 12 or less\n",
    "updrs1_yr_df = new_updrs1_df[new_updrs1_df['visit_month'] <= 12]\n",
    "updrs1_yr_df = updrs1_yr_df.drop(columns=['updrs_1_cat'])\n",
    "updrs1_yr_df.rename(columns={'updrs_1_max_cat': 'updrs_1_cat'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max category for each patient\n",
    "max_df = new_updrs2_df.groupby(['patient_id'])['updrs_2_cat'].max().reset_index()\n",
    "max_df = max_df.rename(columns={'updrs_2_cat': 'updrs_2_max_cat'})\n",
    "# merge the max category with the original dataframe\n",
    "new_updrs2_df = new_updrs2_df.merge(max_df, on=['patient_id'], how='left')\n",
    "# take only the visit months that are 12 or less\n",
    "updrs2_yr_df = new_updrs2_df[new_updrs2_df['visit_month'] <= 12]\n",
    "updrs2_yr_df = updrs2_yr_df.drop(columns=['updrs_2_cat'])\n",
    "updrs2_yr_df.rename(columns={'updrs_2_max_cat': 'updrs_2_cat'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the max category for each patient\n",
    "max_df = new_updrs3_df.groupby(['patient_id'])['updrs_3_cat'].max().reset_index()\n",
    "max_df = max_df.rename(columns={'updrs_3_cat': 'updrs_3_max_cat'})\n",
    "# merge the max category with the original dataframe\n",
    "new_updrs3_df = new_updrs3_df.merge(max_df, on=['patient_id'], how='left')\n",
    "# take only the visit months that are 12 or less\n",
    "updrs3_yr_df = new_updrs3_df[new_updrs3_df['visit_month'] <= 12]\n",
    "updrs3_yr_df = updrs3_yr_df.drop(columns=['updrs_3_cat'])\n",
    "updrs3_yr_df.rename(columns={'updrs_3_max_cat': 'updrs_3_cat'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_forecast_hyperparams_df = pd.read_csv('../data/processed/xgboost_extrafeats_future_cat_hyperparam_results.csv', index_col=0)\n",
    "lgb_forecast_hyperparams_df = pd.read_csv('../data/processed/lgboost_extrafeats_future_cat_hyperparam_results.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.582591</td>\n",
       "      <td>0.534802</td>\n",
       "      <td>0.981408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.657714</td>\n",
       "      <td>0.152731</td>\n",
       "      <td>0.369053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>1.389338</td>\n",
       "      <td>8.496093</td>\n",
       "      <td>0.716661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.001299</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>7.847890</td>\n",
       "      <td>3.242325</td>\n",
       "      <td>1.426564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>5.143446</td>\n",
       "      <td>1.899508</td>\n",
       "      <td>9.592843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.754802</td>\n",
       "      <td>0.520609</td>\n",
       "      <td>0.672934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   updrs_1   updrs_2   updrs_3\n",
       "colsample_bytree  0.582591  0.534802  0.981408\n",
       "learning_rate     0.657714  0.152731  0.369053\n",
       "max_depth         5.000000  7.000000  4.000000\n",
       "min_child_weight  1.389338  8.496093  0.716661\n",
       "min_split_gain    0.001299  0.000076  0.000254\n",
       "reg_alpha         7.847890  3.242325  1.426564\n",
       "reg_lambda        5.143446  1.899508  9.592843\n",
       "subsample         0.754802  0.520609  0.672934"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_forecast_hyperparams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.788955</td>\n",
       "      <td>0.767595</td>\n",
       "      <td>0.864421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.087901</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.001502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.530529</td>\n",
       "      <td>0.527746</td>\n",
       "      <td>0.771962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.236442</td>\n",
       "      <td>0.918564</td>\n",
       "      <td>2.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>2.299038</td>\n",
       "      <td>0.273245</td>\n",
       "      <td>4.413904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>1.647466</td>\n",
       "      <td>2.383878</td>\n",
       "      <td>2.901294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.621922</td>\n",
       "      <td>0.730400</td>\n",
       "      <td>0.768483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   updrs_1   updrs_2   updrs_3\n",
       "colsample_bytree  0.788955  0.767595  0.864421\n",
       "gamma             0.087901  0.001295  0.001502\n",
       "learning_rate     0.530529  0.527746  0.771962\n",
       "max_depth         4.000000  1.000000  7.000000\n",
       "min_child_weight  0.236442  0.918564  2.586700\n",
       "reg_alpha         2.299038  0.273245  4.413904\n",
       "reg_lambda        1.647466  2.383878  2.901294\n",
       "subsample         0.621922  0.730400  0.768483"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_forecast_hyperparams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS: updrs_1\n",
      "Hyperparameters: {'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': None, 'booster': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.7889550744051059, 'gamma': 0.0879005784891575, 'gpu_id': None, 'importance_type': 'gain', 'interaction_constraints': None, 'learning_rate': 0.5305292874654182, 'max_delta_step': None, 'max_depth': 4, 'min_child_weight': 0.2364420495186685, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': 2.299038235392449, 'reg_lambda': 1.6474661293009238, 'scale_pos_weight': None, 'subsample': 0.6219217800767055, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:25:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:26:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:26:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:26:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "UPDRS: updrs_2\n",
      "Hyperparameters: {'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': None, 'booster': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.7675949071590265, 'gamma': 0.0012949460763949, 'gpu_id': None, 'importance_type': 'gain', 'interaction_constraints': None, 'learning_rate': 0.5277457336747287, 'max_delta_step': None, 'max_depth': 1, 'min_child_weight': 0.9185637515873328, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': 0.2732446680425697, 'reg_lambda': 2.383877587901224, 'scale_pos_weight': None, 'subsample': 0.7303996308470037, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:27:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:27:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:27:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:27:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:28:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "UPDRS: updrs_3\n",
      "Hyperparameters: {'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': None, 'booster': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': 0.8644209363959817, 'gamma': 0.0015022831382055, 'gpu_id': None, 'importance_type': 'gain', 'interaction_constraints': None, 'learning_rate': 0.7719623290443977, 'max_delta_step': None, 'max_depth': 7, 'min_child_weight': 2.586700269613973, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 100, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': 4.413904395183996, 'reg_lambda': 2.9012941705774966, 'scale_pos_weight': None, 'subsample': 0.7684830668535508, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:28:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:29:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_forecast_results = dict()\n",
    "\n",
    "for updrs, df in zip(['updrs_1', 'updrs_2', 'updrs_3'], [updrs1_yr_df, updrs2_yr_df, updrs3_yr_df]):\n",
    "    model = prepare_xgboost_model(xgb_forecast_hyperparams_df, updrs)\n",
    "    print(f'UPDRS: {updrs}')\n",
    "    print(f'Hyperparameters: {model.get_params()}')\n",
    "    print('\\n')\n",
    "    auc, acc, prec, recall = cross_fold_validation(df, model, updrs)\n",
    "    xgb_forecast_results[updrs] = {\"auc\":auc,\n",
    "                        \"acc\":acc,\n",
    "                        \"prec\":prec,\n",
    "                        \"recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updrs_1': {'auc': 0.5750637667310504,\n",
       "  'acc': 0.612134241761874,\n",
       "  'prec': 0.5053968776794864,\n",
       "  'recall': 0.40211615039201243},\n",
       " 'updrs_2': {'auc': 0.6332869106706734,\n",
       "  'acc': 0.7154773971672925,\n",
       "  'prec': 0.5601709401709402,\n",
       "  'recall': 0.40265476525538446},\n",
       " 'updrs_3': {'auc': 0.5519635177009493,\n",
       "  'acc': 0.5922675208389494,\n",
       "  'prec': 0.46733614884476954,\n",
       "  'recall': 0.3698171869170501}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_forecast_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBoost Future Categorical Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPDRS: updrs_1\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.5825913965503184, 'importance_type': 'split', 'learning_rate': 0.6577141319875366, 'max_depth': 5, 'min_child_samples': 20, 'min_child_weight': 1.3893377197890882, 'min_split_gain': 0.0012986100523735, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 7.84789041763128, 'reg_lambda': 5.143445719389354, 'silent': 'warn', 'subsample': 0.7548022099472674, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "\n",
      "\n",
      "UPDRS: updrs_2\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.5348020886234701, 'importance_type': 'split', 'learning_rate': 0.1527311989817896, 'max_depth': 7, 'min_child_samples': 20, 'min_child_weight': 8.496093123723053, 'min_split_gain': 7.563070066811084e-05, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 3.2423247022405386, 'reg_lambda': 1.8995084845739276, 'silent': 'warn', 'subsample': 0.5206085732201925, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "\n",
      "\n",
      "UPDRS: updrs_3\n",
      "{'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.9814083427273452, 'importance_type': 'split', 'learning_rate': 0.3690529874118197, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.7166612125791825, 'min_split_gain': 0.0002542563833103, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 1.426563848761312, 'reg_lambda': 9.592843302090284, 'silent': 'warn', 'subsample': 0.672933792104963, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_forecast_results = dict()\n",
    "\n",
    "for updrs, df in zip(['updrs_1', 'updrs_2', 'updrs_3'], [updrs1_yr_df, updrs2_yr_df, updrs3_yr_df]):\n",
    "    model = prepare_lgboost_model(lgb_forecast_hyperparams_df, updrs)\n",
    "    print(f'UPDRS: {updrs}')\n",
    "    print(model.get_params())\n",
    "    print('\\n')\n",
    "    auc, acc, prec, recall = cross_fold_validation(df, model, updrs)\n",
    "    lgb_forecast_results[updrs] = {\"auc\":auc,\n",
    "                        \"acc\":acc,\n",
    "                        \"prec\":prec,\n",
    "                        \"recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updrs_1': {'auc': 0.566277587746803,\n",
       "  'acc': 0.6178930602801229,\n",
       "  'prec': 0.5246477732793522,\n",
       "  'recall': 0.33034213379040966},\n",
       " 'updrs_2': {'auc': 0.5994839866513153,\n",
       "  'acc': 0.7200334935478095,\n",
       "  'prec': 0.5965909090909091,\n",
       "  'recall': 0.27386326779515635},\n",
       " 'updrs_3': {'auc': 0.6205309138820596,\n",
       "  'acc': 0.6668198644389121,\n",
       "  'prec': 0.6028421052631578,\n",
       "  'recall': 0.41389545247274384}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_forecast_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# run cross fold validation on the updrs 1 data\n",
    "updrs1_results = cross_fold_validation(new_updrs1_df, model, 'updrs_1')\n",
    "\n",
    "model = LogisticRegression()\n",
    "updrs2_results = cross_fold_validation(new_updrs2_df, model, 'updrs_2')\n",
    "\n",
    "model = LogisticRegression()\n",
    "updrs3_results = cross_fold_validation(new_updrs3_df, model, 'updrs_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.7996138826729849, 0.0, 0.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.8520731867842569, 0.0, 0.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.8317254466406091, 0.0, 0.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs3_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "# run cross fold validation on the updrs 1 data\n",
    "updrs1_forecast_results = cross_fold_validation(updrs1_yr_df, model, 'updrs_1')\n",
    "\n",
    "model = LogisticRegression()\n",
    "updrs2_forecast_results = cross_fold_validation(updrs2_yr_df, model, 'updrs_2')\n",
    "\n",
    "model = LogisticRegression()\n",
    "updrs3_forecast_results = cross_fold_validation(updrs3_yr_df, model, 'updrs_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.6050245771498612, 0.0, 0.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs1_forecast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.6944309677597058, 0.0, 0.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs2_forecast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.6109384002241145, 0.0, 0.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs3_forecast_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easypy37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
