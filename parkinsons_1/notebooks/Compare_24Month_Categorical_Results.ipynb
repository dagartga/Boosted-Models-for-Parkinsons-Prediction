{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results from Hyperparameter Tuning For Current UPDRS\n",
    "Using the protein and peptide data as well as the visit month, predict the UPDRS value as either Mild, Moderate, or Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the csv file for xgboost hyperparameter tuning\n",
    "xgb_hyperparams_df = pd.read_csv(\"../data/processed/xgboost_future_cat_24m_hyperparam_results.csv\", index_col=0)\n",
    "lgb_hyperparams_df = pd.read_csv(\"../data/processed/lgboost_future_cat_24m_hyperparam_results.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.788359</td>\n",
       "      <td>0.707755</td>\n",
       "      <td>0.964490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.280928</td>\n",
       "      <td>0.882243</td>\n",
       "      <td>0.149543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>11.736254</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.346503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>11.265839</td>\n",
       "      <td>19413.985760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>1.063561</td>\n",
       "      <td>3.480579</td>\n",
       "      <td>4.746389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>4.071927</td>\n",
       "      <td>7.083994</td>\n",
       "      <td>3.508090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.885743</td>\n",
       "      <td>0.988104</td>\n",
       "      <td>0.906154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    updrs_1    updrs_2       updrs_3\n",
       "colsample_bytree   0.788359   0.707755      0.964490\n",
       "learning_rate      0.280928   0.882243      0.149543\n",
       "max_depth          3.000000   8.000000      5.000000\n",
       "min_child_weight  11.736254   0.145900      0.346503\n",
       "min_split_gain     0.000064  11.265839  19413.985760\n",
       "reg_alpha          1.063561   3.480579      4.746389\n",
       "reg_lambda         4.071927   7.083994      3.508090\n",
       "subsample          0.885743   0.988104      0.906154"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_hyperparams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.684247</td>\n",
       "      <td>0.584096</td>\n",
       "      <td>0.996983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.095862</td>\n",
       "      <td>0.004415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.009385</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.077006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.595330</td>\n",
       "      <td>0.137404</td>\n",
       "      <td>1.717018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_alpha</th>\n",
       "      <td>1.665443</td>\n",
       "      <td>2.589235</td>\n",
       "      <td>0.729288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reg_lambda</th>\n",
       "      <td>2.213086</td>\n",
       "      <td>3.162691</td>\n",
       "      <td>4.090971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subsample</th>\n",
       "      <td>0.818436</td>\n",
       "      <td>0.760515</td>\n",
       "      <td>0.813584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   updrs_1   updrs_2   updrs_3\n",
       "colsample_bytree  0.684247  0.584096  0.996983\n",
       "gamma             0.000160  0.095862  0.004415\n",
       "learning_rate     0.009385  0.001702  0.077006\n",
       "max_depth         3.000000  3.000000  4.000000\n",
       "min_child_weight  0.595330  0.137404  1.717018\n",
       "reg_alpha         1.665443  2.589235  0.729288\n",
       "reg_lambda        2.213086  3.162691  4.090971\n",
       "subsample         0.818436  0.760515  0.813584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the protein and updrs data\n",
    "updrs_df = pd.read_csv(\n",
    "        \"~/parkinsons_proj_1/parkinsons_project/parkinsons_1/data/processed/train_24month_protein_data.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>O00391_24m_max_diff</th>\n",
       "      <th>O00391_24m_min_diff</th>\n",
       "      <th>O00533_24m_max_diff</th>\n",
       "      <th>O00533_24m_min_diff</th>\n",
       "      <th>O00584_24m_max_diff</th>\n",
       "      <th>O00584_24m_min_diff</th>\n",
       "      <th>O14498_24m_max_diff</th>\n",
       "      <th>O14498_24m_min_diff</th>\n",
       "      <th>O14773_24m_max_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>YSLTYIYTGLSK_P25311_max</th>\n",
       "      <th>YTTEIIK_P00736_max</th>\n",
       "      <th>YVGGQEHFAHLLILR_P02763_max</th>\n",
       "      <th>YVM(UniMod_35)LPVADQDQC(UniMod_4)IR_P00738_max</th>\n",
       "      <th>YVMLPVADQDQC(UniMod_4)IR_P00738_max</th>\n",
       "      <th>YVNKEIQNAVNGVK_P10909_max</th>\n",
       "      <th>YWGVASFLQK_P02753_max</th>\n",
       "      <th>YYC(UniMod_4)FQGNQFLR_P02790_max</th>\n",
       "      <th>YYTYLIMNK_P01024_max</th>\n",
       "      <th>YYWGGQYTWDMAK_P02675_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7832</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13937.0</td>\n",
       "      <td>13937.0</td>\n",
       "      <td>15188.8</td>\n",
       "      <td>15188.8</td>\n",
       "      <td>10337.2</td>\n",
       "      <td>10337.2</td>\n",
       "      <td>11159.76</td>\n",
       "      <td>...</td>\n",
       "      <td>264123.0</td>\n",
       "      <td>10135.8</td>\n",
       "      <td>4308190.0</td>\n",
       "      <td>287228.0</td>\n",
       "      <td>1188190.0</td>\n",
       "      <td>105262.0</td>\n",
       "      <td>119051.0</td>\n",
       "      <td>530247.0</td>\n",
       "      <td>59186.5</td>\n",
       "      <td>41160.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40874</td>\n",
       "      <td>138.90</td>\n",
       "      <td>138.90</td>\n",
       "      <td>-24110.0</td>\n",
       "      <td>-24110.0</td>\n",
       "      <td>-5059.1</td>\n",
       "      <td>-5059.1</td>\n",
       "      <td>-1893.1</td>\n",
       "      <td>-1893.1</td>\n",
       "      <td>-8046.59</td>\n",
       "      <td>...</td>\n",
       "      <td>225145.0</td>\n",
       "      <td>14107.7</td>\n",
       "      <td>5319090.0</td>\n",
       "      <td>5555.8</td>\n",
       "      <td>1764240.0</td>\n",
       "      <td>89180.0</td>\n",
       "      <td>160973.0</td>\n",
       "      <td>395954.0</td>\n",
       "      <td>52582.4</td>\n",
       "      <td>20639.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23636</td>\n",
       "      <td>-9656.96</td>\n",
       "      <td>-9656.96</td>\n",
       "      <td>-138626.0</td>\n",
       "      <td>-138626.0</td>\n",
       "      <td>2473.7</td>\n",
       "      <td>2473.7</td>\n",
       "      <td>653.6</td>\n",
       "      <td>653.6</td>\n",
       "      <td>10038.74</td>\n",
       "      <td>...</td>\n",
       "      <td>195196.0</td>\n",
       "      <td>12993.9</td>\n",
       "      <td>5184580.0</td>\n",
       "      <td>89648.1</td>\n",
       "      <td>883685.0</td>\n",
       "      <td>62224.2</td>\n",
       "      <td>170098.0</td>\n",
       "      <td>647961.0</td>\n",
       "      <td>64110.0</td>\n",
       "      <td>12694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30119</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>182841.0</td>\n",
       "      <td>112577.0</td>\n",
       "      <td>9552.7</td>\n",
       "      <td>-1674.2</td>\n",
       "      <td>15416.4</td>\n",
       "      <td>12478.9</td>\n",
       "      <td>10746.38</td>\n",
       "      <td>...</td>\n",
       "      <td>185536.0</td>\n",
       "      <td>6870.4</td>\n",
       "      <td>4749580.0</td>\n",
       "      <td>166512.0</td>\n",
       "      <td>921488.0</td>\n",
       "      <td>52793.0</td>\n",
       "      <td>118695.0</td>\n",
       "      <td>501415.0</td>\n",
       "      <td>40288.8</td>\n",
       "      <td>50618.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29417</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>154844.0</td>\n",
       "      <td>117353.0</td>\n",
       "      <td>4852.1</td>\n",
       "      <td>-10615.7</td>\n",
       "      <td>7993.2</td>\n",
       "      <td>6153.3</td>\n",
       "      <td>12549.30</td>\n",
       "      <td>...</td>\n",
       "      <td>195454.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235477.0</td>\n",
       "      <td>428694.0</td>\n",
       "      <td>94570.5</td>\n",
       "      <td>106663.0</td>\n",
       "      <td>624249.0</td>\n",
       "      <td>34506.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  O00391_24m_max_diff  O00391_24m_min_diff  O00533_24m_max_diff  \\\n",
       "0        7832                 0.00                 0.00              13937.0   \n",
       "1       40874               138.90               138.90             -24110.0   \n",
       "2       23636             -9656.96             -9656.96            -138626.0   \n",
       "3       30119                 0.00                 0.00             182841.0   \n",
       "4       29417                 0.00                 0.00             154844.0   \n",
       "\n",
       "   O00533_24m_min_diff  O00584_24m_max_diff  O00584_24m_min_diff  \\\n",
       "0              13937.0              15188.8              15188.8   \n",
       "1             -24110.0              -5059.1              -5059.1   \n",
       "2            -138626.0               2473.7               2473.7   \n",
       "3             112577.0               9552.7              -1674.2   \n",
       "4             117353.0               4852.1             -10615.7   \n",
       "\n",
       "   O14498_24m_max_diff  O14498_24m_min_diff  O14773_24m_max_diff  ...  \\\n",
       "0              10337.2              10337.2             11159.76  ...   \n",
       "1              -1893.1              -1893.1             -8046.59  ...   \n",
       "2                653.6                653.6             10038.74  ...   \n",
       "3              15416.4              12478.9             10746.38  ...   \n",
       "4               7993.2               6153.3             12549.30  ...   \n",
       "\n",
       "   YSLTYIYTGLSK_P25311_max  YTTEIIK_P00736_max  YVGGQEHFAHLLILR_P02763_max  \\\n",
       "0                 264123.0             10135.8                   4308190.0   \n",
       "1                 225145.0             14107.7                   5319090.0   \n",
       "2                 195196.0             12993.9                   5184580.0   \n",
       "3                 185536.0              6870.4                   4749580.0   \n",
       "4                 195454.0                 0.0                         0.0   \n",
       "\n",
       "   YVM(UniMod_35)LPVADQDQC(UniMod_4)IR_P00738_max  \\\n",
       "0                                        287228.0   \n",
       "1                                          5555.8   \n",
       "2                                         89648.1   \n",
       "3                                        166512.0   \n",
       "4                                        235477.0   \n",
       "\n",
       "   YVMLPVADQDQC(UniMod_4)IR_P00738_max  YVNKEIQNAVNGVK_P10909_max  \\\n",
       "0                            1188190.0                   105262.0   \n",
       "1                            1764240.0                    89180.0   \n",
       "2                             883685.0                    62224.2   \n",
       "3                             921488.0                    52793.0   \n",
       "4                             428694.0                    94570.5   \n",
       "\n",
       "   YWGVASFLQK_P02753_max  YYC(UniMod_4)FQGNQFLR_P02790_max  \\\n",
       "0               119051.0                          530247.0   \n",
       "1               160973.0                          395954.0   \n",
       "2               170098.0                          647961.0   \n",
       "3               118695.0                          501415.0   \n",
       "4               106663.0                          624249.0   \n",
       "\n",
       "   YYTYLIMNK_P01024_max  YYWGGQYTWDMAK_P02675_max  \n",
       "0               59186.5                   41160.9  \n",
       "1               52582.4                   20639.5  \n",
       "2               64110.0                   12694.0  \n",
       "3               40288.8                   50618.6  \n",
       "4               34506.0                       0.0  \n",
       "\n",
       "[5 rows x 4785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the updrs of interest\n",
    "# the updrs_1_max is the target, which means the highest categorical value\n",
    "# 0 is mild parkinsons, and 1 is moderate to severe parkinsons as the max\n",
    "updrs1_df = updrs_df.drop(columns=[\"updrs_2_max\", \"updrs_3_max\"])\n",
    "updrs2_df = updrs_df.drop(columns=[\"updrs_1_max\", \"updrs_3_max\"])\n",
    "updrs3_df = updrs_df.drop(columns=[\"updrs_1_max\", \"updrs_2_max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    122\n",
       "1.0     72\n",
       "Name: updrs_1_max, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs1_df['updrs_1_max'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142\n",
       "1.0     52\n",
       "Name: updrs_2_max, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs2_df['updrs_2_max'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    129\n",
       "1.0     65\n",
       "Name: updrs_3_max, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updrs3_df['updrs_3_max'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kfolds(df, updrs):\n",
    "    # create a new column for kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "\n",
    "    # randomize the rows of the data\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # calculate the number of bins using Sturge's rule\n",
    "    # I am using the max here to ensure that the number of bins is at least 5\n",
    "    # and at most 12\n",
    "    num_bins = int(np.floor(1 + np.log2(len(df))))\n",
    "\n",
    "    # bin targets\n",
    "    df.loc[:, \"bins\"] = pd.cut(df[f\"{updrs}_max\"], bins=num_bins, labels=False)\n",
    "\n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # fill the new kfold column\n",
    "    # note that instead of targets we are using bins!\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X=df, y=df.bins.values)):\n",
    "        df.loc[val_idx, \"kfold\"] = fold\n",
    "\n",
    "    # drop the bins column\n",
    "    df = df.drop(\"bins\", axis=1)\n",
    "\n",
    "    # return dataframe with folds\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add kfolds to the df\n",
    "updrs1_df = create_kfolds(updrs1_df, 'updrs_1')\n",
    "updrs2_df = create_kfolds(updrs2_df, 'updrs_2')\n",
    "updrs3_df = create_kfolds(updrs3_df, 'updrs_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_fold_validation(df, model, target):\n",
    "\n",
    "    updrs_results = dict()\n",
    "    \n",
    "    for fold in range(0, 5):\n",
    "        # get the train and test data for the current fold\n",
    "        train = df[df['kfold'] != fold].reset_index(drop=True)\n",
    "        test = df[df['kfold'] == fold].reset_index(drop=True)\n",
    "\n",
    "        # get the train and test data for the current fold\n",
    "        drop_cols = ['patient_id', f'{target}_max', 'kfold']\n",
    "        X_train = train.drop(columns=drop_cols)\n",
    "        y_train = train[f'{target}_max']\n",
    "        X_test = test.drop(columns=drop_cols)\n",
    "        y_test = test[f'{target}_max']\n",
    "\n",
    "        # train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # make predictions\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "\n",
    "        # save the results\n",
    "        updrs_results[f'{target}_fold_{fold}'] = {\n",
    "            'auc_score': roc_auc_score(y_test, preds),\n",
    "            'acc_score': accuracy_score(y_test, preds),\n",
    "            'precision_score': precision_score(y_test, preds),\n",
    "            'recall_score': recall_score(y_test, preds),\n",
    "        }\n",
    "        \n",
    "    mean_auc = np.mean([updrs_results[f'{target}_fold_{fold}']['auc_score'] for fold in range(0, 5)])\n",
    "    mean_acc = np.mean([updrs_results[f'{target}_fold_{fold}']['acc_score'] for fold in range(0, 5)])\n",
    "    mean_precision = np.mean([updrs_results[f'{target}_fold_{fold}']['precision_score'] for fold in range(0, 5)])\n",
    "    mean_recall = np.mean([updrs_results[f'{target}_fold_{fold}']['recall_score'] for fold in range(0, 5)])\n",
    "    \n",
    "    return mean_auc, mean_acc, mean_precision, mean_recall\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.684247</td>\n",
       "      <td>0.584096</td>\n",
       "      <td>0.996983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.095862</td>\n",
       "      <td>0.004415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.009385</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.077006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>0.595330</td>\n",
       "      <td>0.137404</td>\n",
       "      <td>1.717018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   updrs_1   updrs_2   updrs_3\n",
       "colsample_bytree  0.684247  0.584096  0.996983\n",
       "gamma             0.000160  0.095862  0.004415\n",
       "learning_rate     0.009385  0.001702  0.077006\n",
       "max_depth         3.000000  3.000000  4.000000\n",
       "min_child_weight  0.595330  0.137404  1.717018"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_hyperparams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xgboost_model(xgb_hyperparams_df, target):\n",
    "    # train the model using the hyperparameters from the hyperparameter tuning\n",
    "    updrs_hp = xgb_hyperparams_df[target].to_dict()\n",
    "    updrs_hp['max_depth'] = int(updrs_hp['max_depth'])\n",
    "    model = XGBClassifier(**updrs_hp)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': True,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': 0.6842473934580278,\n",
       " 'gamma': 0.0001595641595819,\n",
       " 'gpu_id': None,\n",
       " 'importance_type': 'gain',\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 0.0093846672717342,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 0.5953295257830465,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 1.6654430506226268,\n",
       " 'reg_lambda': 2.213085505829708,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 0.8184363274620908,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model function\n",
    "model = prepare_xgboost_model(xgb_hyperparams_df, 'updrs_1')\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:48:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_results = dict()\n",
    "\n",
    "for updrs, df in zip(['updrs_1', 'updrs_2', 'updrs_3'], [updrs1_df, updrs2_df, updrs3_df]):\n",
    "    model = prepare_xgboost_model(xgb_hyperparams_df, updrs)\n",
    "    auc, acc, prec, recall = cross_fold_validation(df, model, updrs)\n",
    "    xgb_results[updrs] = {\"auc\":auc,\n",
    "                        \"acc\":acc,\n",
    "                        \"prec\":prec,\n",
    "                        \"recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updrs_1': {'auc': 0.536952380952381,\n",
       "  'acc': 0.6183535762483131,\n",
       "  'prec': 0.475,\n",
       "  'recall': 0.22190476190476188},\n",
       " 'updrs_2': {'auc': 0.5184012539184953,\n",
       "  'acc': 0.7218623481781377,\n",
       "  'prec': 0.5066666666666666,\n",
       "  'recall': 0.07818181818181817},\n",
       " 'updrs_3': {'auc': 0.5226153846153846,\n",
       "  'acc': 0.639136302294197,\n",
       "  'prec': 0.43272727272727274,\n",
       "  'recall': 0.16923076923076924}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Classifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lgboost_model(lgb_hyperparams_df, target):\n",
    "    # train the model using the hyperparameters from the hyperparameter tuning\n",
    "    updrs_hp = lgb_hyperparams_df[target].to_dict()\n",
    "    updrs_hp['max_depth'] = int(updrs_hp['max_depth'])\n",
    "    model = LGBMClassifier(**updrs_hp)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colsample_bytree</th>\n",
       "      <td>0.788359</td>\n",
       "      <td>0.707755</td>\n",
       "      <td>0.964490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>0.280928</td>\n",
       "      <td>0.882243</td>\n",
       "      <td>0.149543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_child_weight</th>\n",
       "      <td>11.736254</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.346503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_split_gain</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>11.265839</td>\n",
       "      <td>19413.985760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    updrs_1    updrs_2       updrs_3\n",
       "colsample_bytree   0.788359   0.707755      0.964490\n",
       "learning_rate      0.280928   0.882243      0.149543\n",
       "max_depth          3.000000   8.000000      5.000000\n",
       "min_child_weight  11.736254   0.145900      0.346503\n",
       "min_split_gain     0.000064  11.265839  19413.985760"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_hyperparams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dagart\\anaconda3\\envs\\easypy37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lgb_results = dict()\n",
    "\n",
    "for updrs, df in zip(['updrs_1', 'updrs_2', 'updrs_3'], [updrs1_df, updrs2_df, updrs3_df]):\n",
    "    model = prepare_lgboost_model(lgb_hyperparams_df, updrs)\n",
    "    auc, acc, prec, recall = cross_fold_validation(df, model, updrs)\n",
    "    lgb_results[updrs] = {\"auc\":auc,\n",
    "                        \"acc\":acc,\n",
    "                        \"prec\":prec,\n",
    "                        \"recall\":recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updrs_1': {'auc': 0.5789285714285715,\n",
       "  'acc': 0.6340080971659919,\n",
       "  'prec': 0.5111111111111111,\n",
       "  'recall': 0.3628571428571429},\n",
       " 'updrs_2': {'auc': 0.7084684281236007,\n",
       "  'acc': 0.6183535762483131,\n",
       "  'prec': 0.40543290043290037,\n",
       "  'recall': 0.9036363636363637},\n",
       " 'updrs_3': {'auc': 0.5,\n",
       "  'acc': 0.6649122807017543,\n",
       "  'prec': 0.0,\n",
       "  'recall': 0.0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = updrs1_df[updrs1_df['kfold'] != 4].reset_index(drop=True)\n",
    "test_df = updrs1_df[updrs1_df['kfold'] == 4].reset_index(drop=True)\n",
    "X_train = train_df.drop(columns=['patient_id', 'kfold', 'updrs_1_max'])\n",
    "y_train = train_df['updrs_1_max']\n",
    "X_test = test_df.drop(columns=['patient_id', 'kfold', 'updrs_1_max'])\n",
    "y_test = test_df['updrs_1_max']\n",
    "\n",
    "model = prepare_lgboost_model(lgb_hyperparams_df, 'updrs_1')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_df['preds'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updrs_1_max</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    updrs_1_max  preds\n",
       "0           1.0    1.0\n",
       "1           0.0    0.0\n",
       "2           0.0    0.0\n",
       "3           0.0    0.0\n",
       "4           0.0    0.0\n",
       "5           1.0    0.0\n",
       "6           1.0    1.0\n",
       "7           1.0    1.0\n",
       "8           0.0    1.0\n",
       "9           0.0    0.0\n",
       "10          1.0    0.0\n",
       "11          0.0    1.0\n",
       "12          0.0    0.0\n",
       "13          1.0    0.0\n",
       "14          0.0    0.0\n",
       "15          1.0    1.0\n",
       "16          0.0    1.0\n",
       "17          1.0    0.0\n",
       "18          1.0    0.0\n",
       "19          0.0    0.0\n",
       "20          1.0    0.0\n",
       "21          0.0    0.0\n",
       "22          1.0    0.0\n",
       "23          0.0    0.0\n",
       "24          1.0    0.0\n",
       "25          0.0    0.0\n",
       "26          0.0    0.0\n",
       "27          0.0    0.0\n",
       "28          0.0    1.0\n",
       "29          0.0    0.0\n",
       "30          0.0    0.0\n",
       "31          0.0    0.0\n",
       "32          0.0    0.0\n",
       "33          1.0    1.0\n",
       "34          1.0    1.0\n",
       "35          0.0    0.0\n",
       "36          0.0    1.0\n",
       "37          0.0    1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['updrs_1_max', 'preds']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easypy37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
