{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dagartallison/parkinsons-submission-v1?scriptVersionId=127412302\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/amp-pd')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.671732Z","iopub.execute_input":"2023-04-27T06:53:02.672383Z","iopub.status.idle":"2023-04-27T06:53:02.676768Z","shell.execute_reply.started":"2023-04-27T06:53:02.672346Z","shell.execute_reply":"2023-04-27T06:53:02.675783Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport amp_pd_peptide\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.702411Z","iopub.execute_input":"2023-04-27T06:53:02.704156Z","iopub.status.idle":"2023-04-27T06:53:02.709663Z","shell.execute_reply.started":"2023-04-27T06:53:02.704114Z","shell.execute_reply":"2023-04-27T06:53:02.708608Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"def preprocess_train_df(train_clin_df, train_prot_df, train_pep_df):\n    '''\n        Takes in the train_clinical_data.csv, train_peptides.csv, train_proteins.csv as pandas dataframes\n        Combines the protein and peptide data names and the joins with the train clinical data\n        The dataframes are stratified kfold based on the target\n        The function creates one dataframe for each target (updrs_1, updrs_2, updrs_3, updrs_4) stored in the final_df dictionary\n        Returns a dictionary of the dataframes for each updrs target\n    '''\n    \n    # drop the medication column\n    train_clin_df = train_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n    \n    # create a column with the UniProt and Peptide name combined\n    train_pep_df['peptide_uniprot'] = train_pep_df['Peptide'] + '_'+ train_pep_df['UniProt']\n\n    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n    train_prot_pivot = train_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n    train_pep_pivot = train_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n\n    # combine the two tables on the visit_id\n    full_prot_train_df = train_prot_pivot.join(train_pep_pivot)\n\n    # fill nan with 0 for this first round\n    full_prot_train_df = full_prot_train_df.fillna(0)\n\n    full_train_df = train_clin_df.merge(full_prot_train_df, how='inner', left_on='visit_id', right_on='visit_id')\n    full_train_df = full_train_df.sample(frac=1).reset_index(drop=True)\n\n    \n    updrs = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n\n    final_dfs = dict()\n\n    for target in updrs:\n    \n        to_remove = [updr for updr in updrs if updr != target]\n        \n        temp_train_df = full_train_df.drop(to_remove, axis=1)\n        temp_train_df = temp_train_df.dropna()\n        \n        # calculate the number of bins by Sturge's rule\n        num_bins = int(np.floor(1 + np.log2(len(full_train_df))))\n        temp_train_df.loc[:, \"bins\"] = pd.cut(temp_train_df[target], bins=num_bins, labels=False)\n\n        temp_train_df = temp_train_df.dropna().reset_index(drop=True)\n        \n        # initiate the kfold class from sklearn\n        kf = StratifiedKFold(n_splits=5)\n        \n        # create a kfold column\n        temp_train_df['kfold'] = -1\n\n        # fill the kfold column\n        for f, (t_, v_) in enumerate(kf.split(X=temp_train_df, y=temp_train_df['bins'].values)):\n            temp_train_df.loc[v_, 'kfold'] = f\n            \n        # drop the bins column\n        temp_train_df = temp_train_df.drop('bins', axis=1)\n        \n     \n\n        final_dfs[target] = temp_train_df\n            \n    return final_dfs","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.728569Z","iopub.execute_input":"2023-04-27T06:53:02.728854Z","iopub.status.idle":"2023-04-27T06:53:02.740827Z","shell.execute_reply.started":"2023-04-27T06:53:02.728828Z","shell.execute_reply":"2023-04-27T06:53:02.739926Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"def smape(y_true, y_pred):\n\n    return round(np.mean(np.abs(y_pred - y_true) / ((np.abs(y_true) + np.abs(y_pred))/2)) * 100, 2)\n\n\n\ndef train_rf_model(df_dict):\n    '''\n        Takes in the preprocesses training dictionary of dataframes \n        Then trains a random forest regressor model on the data\n        Returns a dictionary of models, one for each updrs target\n    '''\n    model_dict = {}\n    visit0_col_dict = {}\n    \n    updr1_model = RandomForestRegressor(random_state = 42)\n    updr2_model = RandomForestRegressor(random_state = 42)\n    updr3_model = RandomForestRegressor(random_state = 42)\n    updr4_model = RandomForestRegressor(random_state = 42)\n    \n    for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n        df = df_dict[updr]\n        df = df.drop(columns=['visit_id', 'patient_id', 'kfold'])\n\n        y_train = df[updr].values\n        df = df.drop(columns=[updr])\n        x_train = df.values\n\n        \n        if updr == 'updrs_1':\n            updr1_model.fit(x_train, y_train)\n            preds = updr1_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr1_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n\n        elif updr == 'updrs_2':\n            updr2_model.fit(x_train, y_train)\n            preds = updr2_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr2_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n\n        elif updr == 'updrs_3':\n            updr3_model.fit(x_train, y_train)\n            preds = updr3_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr3_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n        else:\n            updr4_model.fit(x_train, y_train)\n            preds = updr4_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr4_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n        \n    \n    return model_dict, visit0_col_dict\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.753039Z","iopub.execute_input":"2023-04-27T06:53:02.754965Z","iopub.status.idle":"2023-04-27T06:53:02.768021Z","shell.execute_reply.started":"2023-04-27T06:53:02.754936Z","shell.execute_reply":"2023-04-27T06:53:02.766866Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"markdown","source":"## Create a Model for Forecasting the future months","metadata":{}},{"cell_type":"code","source":"def preprocess_forecast_train_df(preprocessed_train_df, target):\n    '''\n        Takes in the preprocessed training dataframe for a single updrs\n        Returns a dataframe for forecasting which has columns for the updrs of different future visits\n    '''\n    \n    temp_df = preprocessed_train_df[['visit_id', 'patient_id', target, 'visit_month']].sort_values(by=['patient_id', 'visit_month']).reset_index(drop=True)\n    temp_pivot = temp_df.pivot(columns='visit_month', values=target, index='patient_id')\n    temp_pivot = temp_pivot.reset_index()\n    \n    cols = [f'{target}_{month}' for month in temp_pivot.columns[1:]]\n    temp_pivot.columns = ['patient_id'] + cols\n    \n    forecast_final = preprocessed_train_df[preprocessed_train_df['visit_month'] == 0]\n    \n    final_df = forecast_final.merge(temp_pivot, on=['patient_id'], how='left')\n    \n    final_df = final_df.drop(columns=['patient_id', target])\n    if 'kfold' in final_df.columns:\n        final_df = final_df.drop(columns=['kfold'])\n        \n    \n    return final_df","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.776752Z","iopub.execute_input":"2023-04-27T06:53:02.778131Z","iopub.status.idle":"2023-04-27T06:53:02.786469Z","shell.execute_reply.started":"2023-04-27T06:53:02.778083Z","shell.execute_reply":"2023-04-27T06:53:02.785526Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"markdown","source":"### Create the forecasting dataframes","metadata":{}},{"cell_type":"code","source":"def train_forecast(model, processed_forecast_dict, target, month_diff):\n    \n    # results dictionary for the models\n    forecast_model_dict = dict()\n    \n    # get the training dataset\n    df = processed_forecast_dict[target]\n    \n    forecast_cols = [col for col in df.columns if 'updrs' in col]\n\n    drop_cols = [col for col in forecast_cols if col not in  [f'{target}_0', f'{target}_{month_diff}']]\n\n    df = df.drop(columns=drop_cols)\n    df = df.drop(columns=['visit_id', 'visit_month'])\n    df = df.rename(columns={f'{target}_0': target})\n    \n    target_mo = f'{target}_{month_diff}'\n    # drop nan rows for target column\n    df = df.dropna(subset=[target_mo])\n    \n    X, y = df, df[target_mo]\n    \n    X = X.drop([target_mo], axis=1).values\n    \n\n    reg = model\n    reg.fit(X, y)\n    preds = reg.predict(X)\n    \n    r2 = metrics.r2_score(y, preds)\n    mape = metrics.mean_absolute_percentage_error(y, preds)\n    s_mape = smape(y, preds)\n    \n    print(target, month_diff, 'SMAPE:', s_mape)\n    \n    return model, df.drop(columns=target_mo).columns","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.804478Z","iopub.execute_input":"2023-04-27T06:53:02.805015Z","iopub.status.idle":"2023-04-27T06:53:02.814047Z","shell.execute_reply.started":"2023-04-27T06:53:02.804979Z","shell.execute_reply":"2023-04-27T06:53:02.813111Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"def preprocess_test_df(test_clin_df, test_prot_df, test_pep_df):\n    '''\n        Takes in the test data from the csv file in the form of a pandas dataframe\n        Combines the peptide and protein data\n        Outputs the dataframe for inference\n    '''\n    \n    \n    if 'upd23b_clinical_state_on_medication' in test_clin_df.columns:\n        # drop the medication column\n        test_clin_df = test_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n    \n    if 'group_key' in test_clin_df.columns:\n        # drop the group key\n        test_clin_df = test_clin_df.drop(columns=['group_key'])\n    \n    # create a column with the UniProt and Peptide name combined\n    test_pep_df['peptide_uniprot'] = test_pep_df['Peptide'] + '_'+ test_pep_df['UniProt']\n\n    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n    test_prot_pivot = test_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n    test_pep_pivot = test_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n\n    # combine the two tables on the visit_id\n    full_prot_test_df = test_prot_pivot.join(test_pep_pivot)\n\n    # fill nan with 0 \n    full_prot_test_df = full_prot_test_df.fillna(0)\n\n    full_test_df = test_clin_df.merge(full_prot_test_df, how='inner', left_on='visit_id', right_on='visit_id')\n    full_test_df = full_test_df.sample(frac=1).reset_index(drop=True)\n\n    missing_row_id = [x for x in test_clin_df['row_id'] if x not in full_test_df['row_id'].to_list()]\n    filtered_df = test_clin_df[test_clin_df['row_id'].isin(missing_row_id)]\n    imputed_df = filtered_df.drop(columns=['visit_month']).merge(full_test_df.drop(columns=['row_id', 'visit_id']),\n                                                                    how='left', \n                                                                    left_on=['patient_id', 'updrs_test'],\n                                                                    right_on=['patient_id', 'updrs_test'])\n    full_test_df = pd.concat([full_test_df, imputed_df])\n    \n    full_test_df = full_test_df.reset_index(drop=True)\n    \n    # remove the imputed visit month and replace from the test df\n    full_test_df = full_test_df.drop(columns='visit_month').merge(test_df[['row_id', 'visit_month']], how='left', left_on='row_id', right_on='row_id')\n    \n    return full_test_df","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.827281Z","iopub.execute_input":"2023-04-27T06:53:02.827531Z","iopub.status.idle":"2023-04-27T06:53:02.83954Z","shell.execute_reply.started":"2023-04-27T06:53:02.827507Z","shell.execute_reply":"2023-04-27T06:53:02.838684Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"\ndef prepare_model_df(model_df, target, train_cols, visit_month=0):\n    '''\n        model_df is the preprocessed test dataframe which has all of the protein data\n        target is the updrs number\n        train_cols are the list of columns necessary for the model to do the inference\n        visit_month is the month of data we want to filter\n    '''\n\n    # add visit_month if it is not in the model_df.columns\n    if 'visit_month' not in model_df.columns:\n        model_df['visit_month'] = visit_month\n    \n    # start will all the visit_months as 0 for the first prediction\n    model_df['visit_month'] = 0\n    \n    model_df = model_df[model_df['updrs_test'] == target]\n    \n    # find the columns in preds_cols that are not in the model_df.columns\n    not_in_pred_cols = [col for col in train_cols if col not in model_df.columns]\n\n    # create an empty dataframe with the columns in not_in_pred_cols\n    not_in_preds_df = pd.DataFrame(columns=not_in_pred_cols)\n\n    # combine the model_df and the not_in_preds_df so all the needed columns are in dataframe\n    new_model_df = pd.concat([model_df, not_in_preds_df], axis=1)\n    \n    # fill the nan values with 0\n    new_model_df = new_model_df.fillna(0)\n    \n    # keep track of the row_id order for later\n    row_id_df = new_model_df[['row_id']]\n\n    # filter the new_model_df to only include the columns in pred_cols with the correct order\n    return new_model_df[train_cols], row_id_df","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.849226Z","iopub.execute_input":"2023-04-27T06:53:02.850006Z","iopub.status.idle":"2023-04-27T06:53:02.857432Z","shell.execute_reply.started":"2023-04-27T06:53:02.849972Z","shell.execute_reply":"2023-04-27T06:53:02.856321Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":"## Train the models for Visit 0 and the Forecasting\n","metadata":{}},{"cell_type":"code","source":"# read the training data with folds\ntrain_df = pd.read_csv('/kaggle/input/amp-pd/train_clinical_data.csv')\ntrain_prot_df = pd.read_csv('/kaggle/input/amp-pd/train_proteins.csv')\ntrain_pep_df = pd.read_csv('/kaggle/input/amp-pd/train_peptides.csv')\n\ntrain_df_dict = preprocess_train_df(train_df, train_prot_df, train_pep_df)\n\n    \ntrained_models_dict, visit0_col_dict = train_rf_model(train_df_dict)\n    \n\nprocessed_forecast_dict = dict()\n\nfor updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n    \n    forecast_data = train_df_dict[updr]\n    processed_forecast_dict[updr] = preprocess_forecast_train_df(forecast_data, updr)\n    \n    \n    \n    \nforecast_col_dict = {'updrs_1':{6:_, 12:_, 24:_}, 'updrs_2':{6:_, 12:_, 24:_}, 'updrs_3':{6:_, 12:_, 24:_}, 'updrs_4':{6:_, 12:_, 24:_}}\n\nmodel_1_6, model_1_12, model_1_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\nmodel_2_6, model_2_12, model_2_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\nmodel_3_6, model_3_12, model_3_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\nmodel_4_6, model_4_12, model_4_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n\n# store the instantiated models\nforecast_dict = {'updrs_1':{6:model_1_6, 12:model_1_12, 24:model_1_24},\n                 'updrs_2':{6:model_2_6, 12:model_2_12, 24:model_2_24},\n                 'updrs_3':{6:model_3_6, 12:model_3_12, 24:model_3_24},\n                 'updrs_4':{6:model_4_6, 12:model_4_12, 24:model_4_24}}\n\n\nfor updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n    for month_diff in [6, 12, 24]:\n        \n        try:\n            forecast_model, forecast_cols = train_forecast(forecast_dict[updr][month_diff], processed_forecast_dict, updr, month_diff)\n            forecast_dict[updr][month_diff] = forecast_model\n            forecast_col_dict[updr][month_diff] = forecast_cols\n        except:\n            print(f'{updr} {month_diff} forecasting model failed!!!!!')\n            \n            \n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:53:02.876748Z","iopub.execute_input":"2023-04-27T06:53:02.87701Z","iopub.status.idle":"2023-04-27T06:56:56.589731Z","shell.execute_reply.started":"2023-04-27T06:53:02.876986Z","shell.execute_reply":"2023-04-27T06:56:56.588633Z"},"trusted":true},"execution_count":186,"outputs":[{"name":"stdout","text":"SMAPE = 37.43, R2 = 0.8878997850877858, MAPE = 570751132551120.8\nSMAPE = 67.68, R2 = 0.8941040316218785, MAPE = 1877132372775258.5\nSMAPE = 58.69, R2 = 0.9013424873400868, MAPE = 3938989556884275.0\nSMAPE = 129.53, R2 = 0.8711836811844778, MAPE = 1932194623960783.0\nupdrs_1 6 SMAPE: 37.39\nupdrs_1 12 SMAPE: 34.43\nupdrs_1 24 SMAPE: 35.41\nupdrs_2 6 SMAPE: 24.7\nupdrs_2 12 SMAPE: 65.36\nupdrs_2 24 SMAPE: 68.52\nupdrs_3 6 SMAPE: 21.09\nupdrs_3 12 SMAPE: 48.22\nupdrs_3 24 SMAPE: 52.74\nupdrs_4 6 forecasting model failed!!!!!\nupdrs_4 12 SMAPE: 128.07\nupdrs_4 24 SMAPE: 114.13\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Create the Prediction Function","metadata":{}},{"cell_type":"code","source":"def create_submission(test_df, test_prot_df, test_pep_df, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict):\n\n    '''\n    Need to input the following variables:\n\n    test_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test.csv')\n    test_prot_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_proteins.csv')\n    test_pep_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_peptides.csv')\n    visit0_col_dict\n    trained_models_dict\n    forecast_col_dict\n    forecast_dict\n    '''\n    test_preprocessed_df = preprocess_test_df(test_df, test_prot_df, test_pep_df)\n\n\n\n    visit0_df = pd.DataFrame()\n\n\n    final_df = pd.DataFrame()\n\n    # for visit 0\n    for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n    \n        # predict the 0 visit first\n    \n        md_df, row_id = prepare_model_df(test_preprocessed_df, updr, visit0_col_dict[updr], visit_month=0)\n        trained_model = trained_models_dict[updr]\n        preds = trained_model.predict(md_df.values)\n        row_id[f'{updr}'] = preds\n        temp_df = pd.concat([row_id, md_df], axis=1)\n        visit0_df = pd.concat([visit0_df, temp_df])\n\n        for month in [6, 12, 24]:\n            if updr == 'updrs_4' and month == 6:\n                # split the difference between 0 and 12\n                forecast_cols = forecast_col_dict[updr][12]\n                forecast_df = visit0_df.dropna(subset=[updr])\n                forecast_id = forecast_df['row_id']\n                forecast_df = forecast_df[forecast_cols]\n    \n                # get the forecast model\n                forecast_model = forecast_dict[updr][12]\n                preds = forecast_model.predict(forecast_df.values)\n                visit0_preds = forecast_df['updrs_4']\n                impute_preds = (preds + visit0_preds) / 2\n                forecast_df[f'{updr}_{month}'] = impute_preds\n                visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n            \n            else:\n                # predict the 6, 12, and 24 later visits\n                forecast_cols = forecast_col_dict[updr][month]\n                forecast_df = visit0_df.dropna(subset=[updr])\n                forecast_id = forecast_df['row_id']\n                forecast_df = forecast_df[forecast_cols]\n    \n                # get the forecast model\n                forecast_model = forecast_dict[updr][month]\n                preds = forecast_model.predict(forecast_df.values)\n                forecast_df[f'{updr}_{month}'] = preds\n                visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n            \n        final_df = pd.concat([final_df, visit0_df])\n        final_df = final_df.drop_duplicates()\n            \n    pred_df = final_df[[col for col in final_df.columns if col == 'row_id' or col[:5] == 'updrs']]\n\n    melted_df = pd.melt(pred_df, id_vars=['row_id'], value_vars=pred_df.columns[1:])\n    melted_df = melted_df.dropna()\n\n    for i, row in melted_df.iterrows():\n        if row['variable'] in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_0_months'\n        elif row['variable'] in ['updrs_1_6', 'updrs_2_6', 'updrs_3_6', 'updrs_4_6']:\n            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_6_months'\n        elif row['variable'] in ['updrs_1_12', 'updrs_2_12', 'updrs_3_12', 'updrs_4_12']:\n            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_12_months'\n        else:\n            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_24_months'\n        \n    melted_df = melted_df.rename(columns={'value':'rating'}).drop(columns=['variable'])\n    result = melted_df.reset_index(drop=True)\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:56:56.592053Z","iopub.execute_input":"2023-04-27T06:56:56.592469Z","iopub.status.idle":"2023-04-27T06:56:56.609434Z","shell.execute_reply.started":"2023-04-27T06:56:56.59243Z","shell.execute_reply":"2023-04-27T06:56:56.608456Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"markdown","source":"## Submission Through the API","metadata":{}},{"cell_type":"code","source":"env = amp_pd_peptide.make_env()   # initialize the environment\niter_test = env.iter_test()  ","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:56:56.61084Z","iopub.execute_input":"2023-04-27T06:56:56.611488Z","iopub.status.idle":"2023-04-27T06:56:56.623158Z","shell.execute_reply.started":"2023-04-27T06:56:56.61145Z","shell.execute_reply":"2023-04-27T06:56:56.622184Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n        \n    result = create_submission(test, test_proteins, test_peptides, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict)\n\n    env.predict(result)   # register your predictions\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:56:56.625559Z","iopub.execute_input":"2023-04-27T06:56:56.62595Z","iopub.status.idle":"2023-04-27T06:56:58.904265Z","shell.execute_reply.started":"2023-04-27T06:56:56.625914Z","shell.execute_reply":"2023-04-27T06:56:58.903073Z"},"trusted":true},"execution_count":189,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}