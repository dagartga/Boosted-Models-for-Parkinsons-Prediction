{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dagartallison/parkinsons-submission-v1?scriptVersionId=127410712\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/amp-pd')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:05:08.115368Z","iopub.execute_input":"2023-04-27T04:05:08.115785Z","iopub.status.idle":"2023-04-27T04:05:08.14801Z","shell.execute_reply.started":"2023-04-27T04:05:08.115701Z","shell.execute_reply":"2023-04-27T04:05:08.147166Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nimport amp_pd_peptide\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:05:09.076065Z","iopub.execute_input":"2023-04-27T04:05:09.077016Z","iopub.status.idle":"2023-04-27T04:05:09.812464Z","shell.execute_reply.started":"2023-04-27T04:05:09.076979Z","shell.execute_reply":"2023-04-27T04:05:09.811421Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def preprocess_train_df(train_clin_df, train_prot_df, train_pep_df):\n    '''\n        Takes in the train_clinical_data.csv, train_peptides.csv, train_proteins.csv as pandas dataframes\n        Combines the protein and peptide data names and the joins with the train clinical data\n        The dataframes are stratified kfold based on the target\n        The function creates one dataframe for each target (updrs_1, updrs_2, updrs_3, updrs_4) stored in the final_df dictionary\n        Returns a dictionary of the dataframes for each updrs target\n    '''\n    \n    # drop the medication column\n    train_clin_df = train_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n    \n    # create a column with the UniProt and Peptide name combined\n    train_pep_df['peptide_uniprot'] = train_pep_df['Peptide'] + '_'+ train_pep_df['UniProt']\n\n    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n    train_prot_pivot = train_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n    train_pep_pivot = train_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n\n    # combine the two tables on the visit_id\n    full_prot_train_df = train_prot_pivot.join(train_pep_pivot)\n\n    # fill nan with 0 for this first round\n    full_prot_train_df = full_prot_train_df.fillna(0)\n\n    full_train_df = train_clin_df.merge(full_prot_train_df, how='inner', left_on='visit_id', right_on='visit_id')\n    full_train_df = full_train_df.sample(frac=1).reset_index(drop=True)\n\n    \n    updrs = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n\n    final_dfs = dict()\n\n    for target in updrs:\n    \n        to_remove = [updr for updr in updrs if updr != target]\n        \n        temp_train_df = full_train_df.drop(to_remove, axis=1)\n        temp_train_df = temp_train_df.dropna()\n        \n        # calculate the number of bins by Sturge's rule\n        num_bins = int(np.floor(1 + np.log2(len(full_train_df))))\n        temp_train_df.loc[:, \"bins\"] = pd.cut(temp_train_df[target], bins=num_bins, labels=False)\n\n        temp_train_df = temp_train_df.dropna().reset_index(drop=True)\n        \n        # initiate the kfold class from sklearn\n        kf = StratifiedKFold(n_splits=5)\n        \n        # create a kfold column\n        temp_train_df['kfold'] = -1\n\n        # fill the kfold column\n        for f, (t_, v_) in enumerate(kf.split(X=temp_train_df, y=temp_train_df['bins'].values)):\n            temp_train_df.loc[v_, 'kfold'] = f\n            \n        # drop the bins column\n        temp_train_df = temp_train_df.drop('bins', axis=1)\n        \n     \n\n        final_dfs[target] = temp_train_df\n            \n    return final_dfs","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:05:09.81435Z","iopub.execute_input":"2023-04-27T04:05:09.814733Z","iopub.status.idle":"2023-04-27T04:05:09.830397Z","shell.execute_reply.started":"2023-04-27T04:05:09.8147Z","shell.execute_reply":"2023-04-27T04:05:09.82935Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def smape(y_true, y_pred):\n\n    return round(np.mean(np.abs(y_pred - y_true) / ((np.abs(y_true) + np.abs(y_pred))/2)) * 100, 2)\n\n\n\ndef train_rf_model(df_dict):\n    '''\n        Takes in the preprocesses training dictionary of dataframes \n        Then trains a random forest regressor model on the data\n        Returns a dictionary of models, one for each updrs target\n    '''\n    model_dict = {}\n    visit0_col_dict = {}\n    \n    updr1_model = RandomForestRegressor(random_state = 42)\n    updr2_model = RandomForestRegressor(random_state = 42)\n    updr3_model = RandomForestRegressor(random_state = 42)\n    updr4_model = RandomForestRegressor(random_state = 42)\n    \n    for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n        df = df_dict[updr]\n        df = df.drop(columns=['visit_id', 'patient_id', 'kfold'])\n\n        y_train = df[updr].values\n        df = df.drop(columns=[updr])\n        x_train = df.values\n\n        \n        if updr == 'updrs_1':\n            updr1_model.fit(x_train, y_train)\n            preds = updr1_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr1_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n\n        elif updr == 'updrs_2':\n            updr2_model.fit(x_train, y_train)\n            preds = updr2_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr2_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n\n        elif updr == 'updrs_3':\n            updr3_model.fit(x_train, y_train)\n            preds = updr3_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr3_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n        else:\n            updr4_model.fit(x_train, y_train)\n            preds = updr4_model.predict(x_train)\n            r2 = metrics.r2_score(y_train, preds)\n            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n            s_mape = smape(y_train, preds)\n            model_dict[updr] = updr4_model\n            visit0_col_dict[updr] = df.columns\n            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n        \n    \n    return model_dict, visit0_col_dict\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:18:06.027258Z","iopub.execute_input":"2023-04-27T04:18:06.027652Z","iopub.status.idle":"2023-04-27T04:18:06.044165Z","shell.execute_reply.started":"2023-04-27T04:18:06.027619Z","shell.execute_reply":"2023-04-27T04:18:06.042839Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Create a Model for Forecasting the future months","metadata":{}},{"cell_type":"code","source":"def preprocess_forecast_train_df(preprocessed_train_df, target):\n    '''\n        Takes in the preprocessed training dataframe for a single updrs\n        Returns a dataframe for forecasting which has columns for the updrs of different future visits\n    '''\n    \n    temp_df = preprocessed_train_df[['visit_id', 'patient_id', target, 'visit_month']].sort_values(by=['patient_id', 'visit_month']).reset_index(drop=True)\n    temp_pivot = temp_df.pivot(columns='visit_month', values=target, index='patient_id')\n    temp_pivot = temp_pivot.reset_index()\n    \n    cols = [f'{target}_{month}' for month in temp_pivot.columns[1:]]\n    temp_pivot.columns = ['patient_id'] + cols\n    \n    forecast_final = preprocessed_train_df[preprocessed_train_df['visit_month'] == 0]\n    \n    final_df = forecast_final.merge(temp_pivot, on=['patient_id'], how='left')\n    \n    final_df = final_df.drop(columns=['patient_id', target])\n    if 'kfold' in final_df.columns:\n        final_df = final_df.drop(columns=['kfold'])\n        \n    \n    return final_df","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:22:33.764366Z","iopub.execute_input":"2023-04-27T04:22:33.764927Z","iopub.status.idle":"2023-04-27T04:22:33.788099Z","shell.execute_reply.started":"2023-04-27T04:22:33.764857Z","shell.execute_reply":"2023-04-27T04:22:33.783566Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Create the forecasting dataframes","metadata":{}},{"cell_type":"code","source":"def train_forecast(model, processed_forecast_dict, target, month_diff):\n    \n    # results dictionary for the models\n    forecast_model_dict = dict()\n    \n    # get the training dataset\n    df = processed_forecast_dict[target]\n    \n    forecast_cols = [col for col in df.columns if 'updrs' in col]\n\n    drop_cols = [col for col in forecast_cols if col not in  [f'{target}_0', f'{target}_{month_diff}']]\n\n    df = df.drop(columns=drop_cols)\n    df = df.drop(columns=['visit_id', 'visit_month'])\n    df = df.rename(columns={f'{target}_0': target})\n    \n    target_mo = f'{target}_{month_diff}'\n    # drop nan rows for target column\n    df = df.dropna(subset=[target_mo])\n    \n    X, y = df, df[target_mo]\n    \n    X = X.drop([target_mo], axis=1).values\n    \n\n    reg = model\n    reg.fit(X, y)\n    preds = reg.predict(X)\n    \n    r2 = metrics.r2_score(y, preds)\n    mape = metrics.mean_absolute_percentage_error(y, preds)\n    s_mape = smape(y, preds)\n    \n    print(target, month_diff, 'SMAPE:', s_mape)\n    \n    return model, df.drop(columns=target_mo).columns","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:31:42.510043Z","iopub.execute_input":"2023-04-27T04:31:42.510446Z","iopub.status.idle":"2023-04-27T04:31:42.520657Z","shell.execute_reply.started":"2023-04-27T04:31:42.510414Z","shell.execute_reply":"2023-04-27T04:31:42.519459Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def preprocess_test_df(test_clin_df, test_prot_df, test_pep_df):\n    '''\n        Takes in the test data from the csv file in the form of a pandas dataframe\n        Combines the peptide and protein data\n        Outputs the dataframe for inference\n    '''\n    \n    \n    if 'upd23b_clinical_state_on_medication' in test_clin_df.columns:\n        # drop the medication column\n        test_clin_df = test_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n    \n    if 'group_key' in test_clin_df.columns:\n        # drop the group key\n        test_clin_df = test_clin_df.drop(columns=['group_key'])\n    \n    # create a column with the UniProt and Peptide name combined\n    test_pep_df['peptide_uniprot'] = test_pep_df['Peptide'] + '_'+ test_pep_df['UniProt']\n\n    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n    test_prot_pivot = test_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n    test_pep_pivot = test_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n\n    # combine the two tables on the visit_id\n    full_prot_test_df = test_prot_pivot.join(test_pep_pivot)\n\n    # fill nan with 0 \n    full_prot_test_df = full_prot_test_df.fillna(0)\n\n    full_test_df = test_clin_df.merge(full_prot_test_df, how='inner', left_on='visit_id', right_on='visit_id')\n    full_test_df = full_test_df.sample(frac=1).reset_index(drop=True)\n\n    missing_row_id = [x for x in test_clin_df['row_id'] if x not in full_test_df['row_id'].to_list()]\n    filtered_df = test_clin_df[test_clin_df['row_id'].isin(missing_row_id)]\n    imputed_df = filtered_df.drop(columns=['visit_month']).merge(full_test_df.drop(columns=['row_id', 'visit_id']),\n                                                                    how='left', \n                                                                    left_on=['patient_id', 'updrs_test'],\n                                                                    right_on=['patient_id', 'updrs_test'])\n    full_test_df = pd.concat([full_test_df, imputed_df])\n    \n    full_test_df = full_test_df.reset_index(drop=True)\n    \n    # remove the imputed visit month and replace from the test df\n    full_test_df = full_test_df.drop(columns='visit_month').merge(test_df[['row_id', 'visit_month']], how='left', left_on='row_id', right_on='row_id')\n    \n    return full_test_df","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:33:49.956005Z","iopub.execute_input":"2023-04-27T04:33:49.956367Z","iopub.status.idle":"2023-04-27T04:33:49.969357Z","shell.execute_reply.started":"2023-04-27T04:33:49.956337Z","shell.execute_reply":"2023-04-27T04:33:49.968263Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\ndef prepare_model_df(model_df, target, train_cols, visit_month=0):\n    '''\n        model_df is the preprocessed test dataframe which has all of the protein data\n        target is the updrs number\n        train_cols are the list of columns necessary for the model to do the inference\n        visit_month is the month of data we want to filter\n    '''\n\n    # add visit_month if it is not in the model_df.columns\n    if 'visit_month' not in model_df.columns:\n        model_df['visit_month'] = visit_month\n    \n    # start will all the visit_months as 0 for the first prediction\n    model_df['visit_month'] = 0\n    \n    model_df = model_df[model_df['updrs_test'] == target]\n    \n    # find the columns in preds_cols that are not in the model_df.columns\n    not_in_pred_cols = [col for col in train_cols if col not in model_df.columns]\n\n    # create an empty dataframe with the columns in not_in_pred_cols\n    not_in_preds_df = pd.DataFrame(columns=not_in_pred_cols)\n\n    # combine the model_df and the not_in_preds_df so all the needed columns are in dataframe\n    new_model_df = pd.concat([model_df, not_in_preds_df], axis=1)\n    \n    # fill the nan values with 0\n    new_model_df = new_model_df.fillna(0)\n    \n    # keep track of the row_id order for later\n    row_id_df = new_model_df[['row_id']]\n\n    # filter the new_model_df to only include the columns in pred_cols with the correct order\n    return new_model_df[train_cols], row_id_df","metadata":{"execution":{"iopub.status.busy":"2023-04-27T04:56:38.255204Z","iopub.execute_input":"2023-04-27T04:56:38.255577Z","iopub.status.idle":"2023-04-27T04:56:38.263527Z","shell.execute_reply.started":"2023-04-27T04:56:38.255544Z","shell.execute_reply":"2023-04-27T04:56:38.262392Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## Train the models for Visit 0 and the Forecasting\n","metadata":{}},{"cell_type":"code","source":"# read the training data with folds\ntrain_df = pd.read_csv('/kaggle/input/amp-pd/train_clinical_data.csv')\ntrain_prot_df = pd.read_csv('/kaggle/input/amp-pd/train_proteins.csv')\ntrain_pep_df = pd.read_csv('/kaggle/input/amp-pd/train_peptides.csv')\n\ntrain_df_dict = preprocess_train_df(train_df, train_prot_df, train_pep_df)\n\n    \ntrained_models_dict, visit0_col_dict = train_rf_model(train_df_dict)\n    \n\nprocessed_forecast_dict = dict()\n\nfor updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n    \n    forecast_data = train_df_dict[updr]\n    processed_forecast_dict[updr] = preprocess_forecast_train_df(forecast_data, updr)\n    \n    \n    \n    \nforecast_col_dict = {'updrs_1':{6:_, 12:_, 24:_}, 'updrs_2':{6:_, 12:_, 24:_}, 'updrs_3':{6:_, 12:_, 24:_}, 'updrs_4':{6:_, 12:_, 24:_}}\n\nmodel_1_6, model_1_12, model_1_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\nmodel_2_6, model_2_12, model_2_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\nmodel_3_6, model_3_12, model_3_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\nmodel_4_6, model_4_12, model_4_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n\n# store the instantiated models\nforecast_dict = {'updrs_1':{6:model_1_6, 12:model_1_12, 24:model_1_24},\n                 'updrs_2':{6:model_2_6, 12:model_2_12, 24:model_2_24},\n                 'updrs_3':{6:model_3_6, 12:model_3_12, 24:model_3_24},\n                 'updrs_4':{6:model_4_6, 12:model_4_12, 24:model_4_24}}\n\n\nfor updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n    for month_diff in [6, 12, 24]:\n        \n        try:\n            forecast_model, forecast_cols = train_forecast(forecast_dict[updr][month_diff], processed_forecast_dict, updr, month_diff)\n            forecast_dict[updr][month_diff] = forecast_model\n            forecast_col_dict[updr][month_diff] = forecast_cols\n        except:\n            print(f'{updr} {month_diff} forecasting model failed!!!!!')\n            \n            \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Perform the testing predictions","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test.csv')\ntest_prot_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_proteins.csv')\ntest_pep_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_peptides.csv')\n\ntest_preprocessed_df = preprocess_test_df(test_df, test_prot_df, test_pep_df)\n\nmd_df, row_id = prepare_model_df(test_preprocessed_df, 'updrs_1', visit0_col_dict['updrs_1'], visit_month=0)\n\n\nvisit0_df = pd.DataFrame()\n\n\nfinal_df = pd.DataFrame()\n\n# for visit 0\nfor updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n    \n    # predict the 0 visit first\n    \n    md_df, row_id = prepare_model_df(test_preprocessed_df, updr, visit0_col_dict[updr], visit_month=0)\n    trained_model = trained_models_dict[updr]\n    preds = trained_model.predict(md_df.values)\n    row_id[f'{updr}'] = preds\n    temp_df = pd.concat([row_id, md_df], axis=1)\n    visit0_df = pd.concat([visit0_df, temp_df])\n\n    for month in [6, 12, 24]:\n        if updr == 'updrs_4' and month == 6:\n            # split the difference between 0 and 12\n            forecast_cols = forecast_col_dict[updr][12]\n            forecast_df = visit0_df.dropna(subset=[updr])\n            forecast_id = forecast_df['row_id']\n            forecast_df = forecast_df[forecast_cols]\n    \n            # get the forecast model\n            forecast_model = forecast_dict[updr][12]\n            preds = forecast_model.predict(forecast_df.values)\n            visit0_preds = forecast_df['updrs_4']\n            impute_preds = (preds + visit0_preds) / 2\n            forecast_df[f'{updr}_{month}'] = impute_preds\n            visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n            \n        else:\n            # predict the 6, 12, and 24 later visits\n            forecast_cols = forecast_col_dict[updr][month]\n            forecast_df = visit0_df.dropna(subset=[updr])\n            forecast_id = forecast_df['row_id']\n            forecast_df = forecast_df[forecast_cols]\n    \n            # get the forecast model\n            forecast_model = forecast_dict[updr][month]\n            preds = forecast_model.predict(forecast_df.values)\n            forecast_df[f'{updr}_{month}'] = preds\n            visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n            \n    final_df = pd.concat([final_df, visit0_df])\n    final_df = final_df.drop_duplicates()\n            \npred_df = final_df[[col for col in final_df.columns if col == 'row_id' or col[:5] == 'updrs']]\n\nmelted_df = pd.melt(pred_df, id_vars=['row_id'], value_vars=pred_df.columns[1:])\nmelted_df = melted_df.dropna()\n\nfor i, row in melted_df.iterrows():\n    if row['variable'] in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n        melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_0_months'\n    elif row['variable'] in ['updrs_1_6', 'updrs_2_6', 'updrs_3_6', 'updrs_4_6']:\n        melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_6_months'\n    elif row['variable'] in ['updrs_1_12', 'updrs_2_12', 'updrs_3_12', 'updrs_4_12']:\n        melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_12_months'\n    else:\n        melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_24_months'\n        \nmelted_df = melted_df.rename(columns={'value':'rating'}).drop(columns=['variable'])\nmelted_df = melted_df.reset_index(drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simple Linear Regression Model for testing how to Submit via the API","metadata":{}},{"cell_type":"code","source":"model = {}\ntarget = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\ntrain = pd.read_csv(\"/kaggle/input/amp-pd/train_clinical_data.csv\")\n\n\nfor u in target:\n        \n    # Drop NAs\n    temp = train.dropna(subset=[u]) \n    \n    # Train data\n    X = temp['visit_month']\n    y = temp[u]\n        \n    trained = LinearRegression().fit(X.values.reshape(-1, 1), y)\n    \n    # Save model\n    model[u] = trained","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:38:12.861833Z","iopub.execute_input":"2023-04-27T06:38:12.862242Z","iopub.status.idle":"2023-04-27T06:38:12.884874Z","shell.execute_reply.started":"2023-04-27T06:38:12.862208Z","shell.execute_reply":"2023-04-27T06:38:12.884052Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"def get_predictions(my_train, pro, model):\n\n    # Forecast\n    my_train = my_train.fillna(0)\n    \n    for u in target:\n        \n        # Here is where we will save the final results\n        my_train['result_' + str(u)] = 0\n  \n        # Predict    \n        X = my_train[\"visit_month\"]\n        \n        if u == 'updrs_4':\n            my_train['result_' + str(u)] = 0\n        else:\n            my_train['result_' + str(u)] = np.ceil(model[u].predict(X.values.reshape(-1, 1)))\n\n        \n    # Format for final submission\n    result = pd.DataFrame()\n\n    for m in [0, 6, 12, 24]:\n        for u in [1, 2, 3, 4]:\n\n            temp = my_train[[\"visit_id\", \"result_updrs_\" + str(u)]]\n            temp[\"prediction_id\"] = temp[\"visit_id\"] + \"_updrs_\" + str(u) + \"_plus_\" + str(m) + \"_months\"\n            temp[\"rating\"] = temp[\"result_updrs_\" + str(u)]\n            temp = temp [['prediction_id', 'rating']]\n\n            result = result.append(temp)            \n    result = result.drop_duplicates(subset=['prediction_id', 'rating'])\n\n    return result\n\n# Run once to check results\nget_predictions(train, None, model)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:38:13.876849Z","iopub.execute_input":"2023-04-27T06:38:13.877254Z","iopub.status.idle":"2023-04-27T06:38:13.989666Z","shell.execute_reply.started":"2023-04-27T06:38:13.877222Z","shell.execute_reply":"2023-04-27T06:38:13.988738Z"},"trusted":true},"execution_count":173,"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"                        prediction_id  rating\n0          55_0_updrs_1_plus_0_months     7.0\n1          55_3_updrs_1_plus_0_months     7.0\n2          55_6_updrs_1_plus_0_months     7.0\n3          55_9_updrs_1_plus_0_months     7.0\n4         55_12_updrs_1_plus_0_months     7.0\n...                               ...     ...\n2610  65043_48_updrs_4_plus_24_months     0.0\n2611  65043_54_updrs_4_plus_24_months     0.0\n2612  65043_60_updrs_4_plus_24_months     0.0\n2613  65043_72_updrs_4_plus_24_months     0.0\n2614  65043_84_updrs_4_plus_24_months     0.0\n\n[41840 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55_0_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55_3_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>55_6_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>55_9_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>55_12_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2610</th>\n      <td>65043_48_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2611</th>\n      <td>65043_54_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2612</th>\n      <td>65043_60_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2613</th>\n      <td>65043_72_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2614</th>\n      <td>65043_84_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>41840 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test.csv')\ntest_prot_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_proteins.csv')\ntest_pep_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_peptides.csv')\n\ntrain_df = pd.read_csv('/kaggle/input/amp-pd/train_clinical_data.csv')\ntrain_prot_df = pd.read_csv('/kaggle/input/amp-pd/train_proteins.csv')\ntrain_pep_df = pd.read_csv('/kaggle/input/amp-pd/train_peptides.csv')\n\n# Run once to check results\nlr_preds = get_predictions(test_df, test_prot_df, model)\n\nlr_preds\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:38:17.58716Z","iopub.execute_input":"2023-04-27T06:38:17.587514Z","iopub.status.idle":"2023-04-27T06:38:18.262132Z","shell.execute_reply.started":"2023-04-27T06:38:17.587483Z","shell.execute_reply":"2023-04-27T06:38:18.260968Z"},"trusted":true},"execution_count":174,"outputs":[{"execution_count":174,"output_type":"execute_result","data":{"text/plain":"                     prediction_id  rating\n0     3342_0_updrs_1_plus_0_months     7.0\n4    50423_0_updrs_1_plus_0_months     7.0\n8     3342_6_updrs_1_plus_0_months     7.0\n12   50423_6_updrs_1_plus_0_months     7.0\n0     3342_0_updrs_2_plus_0_months     6.0\n..                             ...     ...\n12  50423_6_updrs_3_plus_24_months    18.0\n0    3342_0_updrs_4_plus_24_months     0.0\n4   50423_0_updrs_4_plus_24_months     0.0\n8    3342_6_updrs_4_plus_24_months     0.0\n12  50423_6_updrs_4_plus_24_months     0.0\n\n[64 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3342_0_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50423_0_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3342_6_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>50423_6_updrs_1_plus_0_months</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3342_0_updrs_2_plus_0_months</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>50423_6_updrs_3_plus_24_months</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>3342_0_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50423_0_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3342_6_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>50423_6_updrs_4_plus_24_months</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>64 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Submission Through the API","metadata":{}},{"cell_type":"code","source":"env = amp_pd_peptide.make_env()   # initialize the environment\niter_test = env.iter_test()  ","metadata":{"execution":{"iopub.status.busy":"2023-04-23T18:52:13.379853Z","iopub.execute_input":"2023-04-23T18:52:13.380848Z","iopub.status.idle":"2023-04-23T18:52:13.388486Z","shell.execute_reply.started":"2023-04-23T18:52:13.380789Z","shell.execute_reply":"2023-04-23T18:52:13.386864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n        \n    result = create_submission_df(test, test_proteins, test_pep_df)\n\n    env.predict(result)   # register your predictions\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T18:52:13.391025Z","iopub.execute_input":"2023-04-23T18:52:13.391891Z","iopub.status.idle":"2023-04-23T18:52:13.591182Z","shell.execute_reply.started":"2023-04-23T18:52:13.391834Z","shell.execute_reply":"2023-04-23T18:52:13.589883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}