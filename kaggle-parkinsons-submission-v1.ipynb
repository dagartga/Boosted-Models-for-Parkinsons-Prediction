{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dagartallison/parkinsons-submission-v1?scriptVersionId=127526190\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"a3be2686","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:56.321339Z","iopub.status.busy":"2023-04-28T05:08:56.320882Z","iopub.status.idle":"2023-04-28T05:08:56.331298Z","shell.execute_reply":"2023-04-28T05:08:56.330508Z"},"papermill":{"duration":0.019798,"end_time":"2023-04-28T05:08:56.333339","exception":false,"start_time":"2023-04-28T05:08:56.313541","status":"completed"},"tags":[]},"outputs":[],"source":["import sys\n","sys.path.append('/kaggle/input/amp-pd')"]},{"cell_type":"code","execution_count":2,"id":"4850a487","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:56.344952Z","iopub.status.busy":"2023-04-28T05:08:56.343598Z","iopub.status.idle":"2023-04-28T05:08:57.57935Z","shell.execute_reply":"2023-04-28T05:08:57.578333Z"},"papermill":{"duration":1.243483,"end_time":"2023-04-28T05:08:57.581816","exception":false,"start_time":"2023-04-28T05:08:56.338333","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","import amp_pd_peptide\n","from sklearn.linear_model import LinearRegression\n","from sklearn import metrics\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"id":"8dc0d2e7","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:57.593855Z","iopub.status.busy":"2023-04-28T05:08:57.593562Z","iopub.status.idle":"2023-04-28T05:08:57.606738Z","shell.execute_reply":"2023-04-28T05:08:57.605794Z"},"papermill":{"duration":0.021844,"end_time":"2023-04-28T05:08:57.609005","exception":false,"start_time":"2023-04-28T05:08:57.587161","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess_train_df(train_clin_df, train_prot_df, train_pep_df):\n","    '''\n","        Takes in the train_clinical_data.csv, train_peptides.csv, train_proteins.csv as pandas dataframes\n","        Combines the protein and peptide data names and the joins with the train clinical data\n","        The dataframes are stratified kfold based on the target\n","        The function creates one dataframe for each target (updrs_1, updrs_2, updrs_3, updrs_4) stored in the final_df dictionary\n","        Returns a dictionary of the dataframes for each updrs target\n","    '''\n","    \n","    # drop the medication column\n","    train_clin_df = train_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n","    \n","    # create a column with the UniProt and Peptide name combined\n","    train_pep_df['peptide_uniprot'] = train_pep_df['Peptide'] + '_'+ train_pep_df['UniProt']\n","\n","    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n","    train_prot_pivot = train_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n","    train_pep_pivot = train_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n","\n","    # combine the two tables on the visit_id\n","    full_prot_train_df = train_prot_pivot.join(train_pep_pivot)\n","\n","    # fill nan with 0 for this first round\n","    full_prot_train_df = full_prot_train_df.fillna(0)\n","\n","    full_train_df = train_clin_df.merge(full_prot_train_df, how='inner', left_on='visit_id', right_on='visit_id')\n","    full_train_df = full_train_df.sample(frac=1).reset_index(drop=True)\n","\n","    \n","    updrs = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n","\n","    final_dfs = dict()\n","\n","    for target in updrs:\n","    \n","        to_remove = [updr for updr in updrs if updr != target]\n","        \n","        temp_train_df = full_train_df.drop(to_remove, axis=1)\n","        temp_train_df = temp_train_df.dropna()\n","        \n","        # calculate the number of bins by Sturge's rule\n","        num_bins = int(np.floor(1 + np.log2(len(full_train_df))))\n","        temp_train_df.loc[:, \"bins\"] = pd.cut(temp_train_df[target], bins=num_bins, labels=False)\n","\n","        temp_train_df = temp_train_df.dropna().reset_index(drop=True)\n","        \n","        # initiate the kfold class from sklearn\n","        kf = StratifiedKFold(n_splits=5)\n","        \n","        # create a kfold column\n","        temp_train_df['kfold'] = -1\n","\n","        # fill the kfold column\n","        for f, (t_, v_) in enumerate(kf.split(X=temp_train_df, y=temp_train_df['bins'].values)):\n","            temp_train_df.loc[v_, 'kfold'] = f\n","            \n","        # drop the bins column\n","        temp_train_df = temp_train_df.drop('bins', axis=1)\n","        \n","     \n","\n","        final_dfs[target] = temp_train_df\n","            \n","    return final_dfs"]},{"cell_type":"code","execution_count":4,"id":"4951cf75","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:57.620182Z","iopub.status.busy":"2023-04-28T05:08:57.619555Z","iopub.status.idle":"2023-04-28T05:08:57.63298Z","shell.execute_reply":"2023-04-28T05:08:57.632138Z"},"papermill":{"duration":0.021251,"end_time":"2023-04-28T05:08:57.63506","exception":false,"start_time":"2023-04-28T05:08:57.613809","status":"completed"},"tags":[]},"outputs":[],"source":["def smape(y_true, y_pred):\n","\n","    return round(np.mean(np.abs(y_pred - y_true) / ((np.abs(y_true) + np.abs(y_pred))/2)) * 100, 2)\n","\n","\n","\n","def train_rf_model(df_dict):\n","    '''\n","        Takes in the preprocesses training dictionary of dataframes \n","        Then trains a random forest regressor model on the data\n","        Returns a dictionary of models, one for each updrs target\n","    '''\n","    model_dict = {}\n","    visit0_col_dict = {}\n","    \n","    updr1_model = RandomForestRegressor(random_state = 42)\n","    updr2_model = RandomForestRegressor(random_state = 42)\n","    updr3_model = RandomForestRegressor(random_state = 42)\n","    updr4_model = RandomForestRegressor(random_state = 42)\n","    \n","    for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n","        df = df_dict[updr]\n","        df = df.drop(columns=['visit_id', 'patient_id', 'kfold'])\n","\n","        y_train = df[updr].values\n","        df = df.drop(columns=[updr])\n","        x_train = df.values\n","\n","        \n","        if updr == 'updrs_1':\n","            updr1_model.fit(x_train, y_train)\n","            preds = updr1_model.predict(x_train)\n","            r2 = metrics.r2_score(y_train, preds)\n","            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n","            s_mape = smape(y_train, preds)\n","            model_dict[updr] = updr1_model\n","            visit0_col_dict[updr] = df.columns\n","            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n","\n","        elif updr == 'updrs_2':\n","            updr2_model.fit(x_train, y_train)\n","            preds = updr2_model.predict(x_train)\n","            r2 = metrics.r2_score(y_train, preds)\n","            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n","            s_mape = smape(y_train, preds)\n","            model_dict[updr] = updr2_model\n","            visit0_col_dict[updr] = df.columns\n","            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n","\n","        elif updr == 'updrs_3':\n","            updr3_model.fit(x_train, y_train)\n","            preds = updr3_model.predict(x_train)\n","            r2 = metrics.r2_score(y_train, preds)\n","            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n","            s_mape = smape(y_train, preds)\n","            model_dict[updr] = updr3_model\n","            visit0_col_dict[updr] = df.columns\n","            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n","        else:\n","            updr4_model.fit(x_train, y_train)\n","            preds = updr4_model.predict(x_train)\n","            r2 = metrics.r2_score(y_train, preds)\n","            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n","            s_mape = smape(y_train, preds)\n","            model_dict[updr] = updr4_model\n","            visit0_col_dict[updr] = df.columns\n","            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n","        \n","    \n","    return model_dict, visit0_col_dict\n"]},{"cell_type":"markdown","id":"a55f67c5","metadata":{"papermill":{"duration":0.004683,"end_time":"2023-04-28T05:08:57.644413","exception":false,"start_time":"2023-04-28T05:08:57.63973","status":"completed"},"tags":[]},"source":["## Create a Model for Forecasting the future months"]},{"cell_type":"code","execution_count":5,"id":"6f1289d3","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:57.654842Z","iopub.status.busy":"2023-04-28T05:08:57.654571Z","iopub.status.idle":"2023-04-28T05:08:57.662812Z","shell.execute_reply":"2023-04-28T05:08:57.661997Z"},"papermill":{"duration":0.015645,"end_time":"2023-04-28T05:08:57.664751","exception":false,"start_time":"2023-04-28T05:08:57.649106","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess_forecast_train_df(preprocessed_train_df, target):\n","    '''\n","        Takes in the preprocessed training dataframe for a single updrs\n","        Returns a dataframe for forecasting which has columns for the updrs of different future visits\n","    '''\n","    \n","    temp_df = preprocessed_train_df[['visit_id', 'patient_id', target, 'visit_month']].sort_values(by=['patient_id', 'visit_month']).reset_index(drop=True)\n","    temp_pivot = temp_df.pivot(columns='visit_month', values=target, index='patient_id')\n","    temp_pivot = temp_pivot.reset_index()\n","    \n","    cols = [f'{target}_{month}' for month in temp_pivot.columns[1:]]\n","    temp_pivot.columns = ['patient_id'] + cols\n","    \n","    forecast_final = preprocessed_train_df[preprocessed_train_df['visit_month'] == 0]\n","    \n","    final_df = forecast_final.merge(temp_pivot, on=['patient_id'], how='left')\n","    \n","    final_df = final_df.drop(columns=['patient_id', target])\n","    if 'kfold' in final_df.columns:\n","        final_df = final_df.drop(columns=['kfold'])\n","        \n","    \n","    return final_df"]},{"cell_type":"markdown","id":"1d00c3b3","metadata":{"papermill":{"duration":0.004348,"end_time":"2023-04-28T05:08:57.673748","exception":false,"start_time":"2023-04-28T05:08:57.6694","status":"completed"},"tags":[]},"source":["### Create the forecasting dataframes"]},{"cell_type":"code","execution_count":6,"id":"0823e674","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:57.685501Z","iopub.status.busy":"2023-04-28T05:08:57.683957Z","iopub.status.idle":"2023-04-28T05:08:57.692923Z","shell.execute_reply":"2023-04-28T05:08:57.692099Z"},"papermill":{"duration":0.016562,"end_time":"2023-04-28T05:08:57.695071","exception":false,"start_time":"2023-04-28T05:08:57.678509","status":"completed"},"tags":[]},"outputs":[],"source":["def train_forecast(model, processed_forecast_dict, target, month_diff):\n","    \n","    # results dictionary for the models\n","    forecast_model_dict = dict()\n","    \n","    # get the training dataset\n","    df = processed_forecast_dict[target]\n","    \n","    forecast_cols = [col for col in df.columns if 'updrs' in col]\n","\n","    drop_cols = [col for col in forecast_cols if col not in  [f'{target}_0', f'{target}_{month_diff}']]\n","\n","    df = df.drop(columns=drop_cols)\n","    df = df.drop(columns=['visit_id', 'visit_month'])\n","    df = df.rename(columns={f'{target}_0': target})\n","    \n","    target_mo = f'{target}_{month_diff}'\n","    # drop nan rows for target column\n","    df = df.dropna(subset=[target_mo])\n","    \n","    X, y = df, df[target_mo]\n","    \n","    X = X.drop([target_mo], axis=1).values\n","    \n","\n","    reg = model\n","    reg.fit(X, y)\n","    preds = reg.predict(X)\n","    \n","    r2 = metrics.r2_score(y, preds)\n","    mape = metrics.mean_absolute_percentage_error(y, preds)\n","    s_mape = smape(y, preds)\n","    \n","    print(target, month_diff, 'SMAPE:', s_mape)\n","    \n","    return model, df.drop(columns=target_mo).columns"]},{"cell_type":"code","execution_count":7,"id":"1805e3b1","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:57.70561Z","iopub.status.busy":"2023-04-28T05:08:57.705337Z","iopub.status.idle":"2023-04-28T05:08:57.715221Z","shell.execute_reply":"2023-04-28T05:08:57.714318Z"},"papermill":{"duration":0.01768,"end_time":"2023-04-28T05:08:57.717452","exception":false,"start_time":"2023-04-28T05:08:57.699772","status":"completed"},"tags":[]},"outputs":[],"source":["def preprocess_test_df(test_clin_df, test_prot_df, test_pep_df):\n","    '''\n","        Takes in the test data from the csv file in the form of a pandas dataframe\n","        Combines the peptide and protein data\n","        Outputs the dataframe for inference\n","    '''\n","    \n","    \n","    if 'upd23b_clinical_state_on_medication' in test_clin_df.columns:\n","        # drop the medication column\n","        test_clin_df = test_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n","    \n","    if 'group_key' in test_clin_df.columns:\n","        # drop the group key\n","        test_clin_df = test_clin_df.drop(columns=['group_key'])\n","    \n","    # create a column with the UniProt and Peptide name combined\n","    test_pep_df['peptide_uniprot'] = test_pep_df['Peptide'] + '_'+ test_pep_df['UniProt']\n","\n","    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n","    test_prot_pivot = test_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n","    test_pep_pivot = test_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n","\n","    # combine the two tables on the visit_id\n","    full_prot_test_df = test_prot_pivot.join(test_pep_pivot)\n","\n","    # fill nan with 0 \n","    full_prot_test_df = full_prot_test_df.fillna(0)\n","\n","    full_test_df = test_clin_df.merge(full_prot_test_df, how='inner', left_on='visit_id', right_on='visit_id')\n","    full_test_df = full_test_df.sample(frac=1).reset_index(drop=True)\n","\n","    missing_row_id = [x for x in test_clin_df['row_id'] if x not in full_test_df['row_id'].to_list()]\n","    filtered_df = test_clin_df[test_clin_df['row_id'].isin(missing_row_id)]\n","    imputed_df = filtered_df.drop(columns=['visit_month']).merge(full_test_df.drop(columns=['row_id', 'visit_id']),\n","                                                                    how='left', \n","                                                                    left_on=['patient_id', 'updrs_test'],\n","                                                                    right_on=['patient_id', 'updrs_test'])\n","    full_test_df = pd.concat([full_test_df, imputed_df])\n","    \n","    full_test_df = full_test_df.reset_index(drop=True)\n","    \n","    # remove the imputed visit month and replace from the test df\n","    full_test_df = full_test_df.drop(columns='visit_month').merge(test_clin_df[['row_id', 'visit_month']], how='left', left_on='row_id', right_on='row_id')\n","    \n","    return full_test_df"]},{"cell_type":"code","execution_count":8,"id":"fd8fee10","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:57.727796Z","iopub.status.busy":"2023-04-28T05:08:57.727528Z","iopub.status.idle":"2023-04-28T05:08:57.734056Z","shell.execute_reply":"2023-04-28T05:08:57.733079Z"},"papermill":{"duration":0.014037,"end_time":"2023-04-28T05:08:57.736118","exception":false,"start_time":"2023-04-28T05:08:57.722081","status":"completed"},"tags":[]},"outputs":[],"source":["\n","def prepare_model_df(model_df, target, train_cols, visit_month=0):\n","    '''\n","        model_df is the preprocessed test dataframe which has all of the protein data\n","        target is the updrs number\n","        train_cols are the list of columns necessary for the model to do the inference\n","        visit_month is the month of data we want to filter\n","    '''\n","\n","    # add visit_month if it is not in the model_df.columns\n","    if 'visit_month' not in model_df.columns:\n","        model_df['visit_month'] = visit_month\n","    \n","    # start will all the visit_months as 0 for the first prediction\n","    model_df['visit_month'] = 0\n","    \n","    model_df = model_df[model_df['updrs_test'] == target]\n","    \n","    # find the columns in preds_cols that are not in the model_df.columns\n","    not_in_pred_cols = [col for col in train_cols if col not in model_df.columns]\n","\n","    # create an empty dataframe with the columns in not_in_pred_cols\n","    not_in_preds_df = pd.DataFrame(columns=not_in_pred_cols)\n","\n","    # combine the model_df and the not_in_preds_df so all the needed columns are in dataframe\n","    new_model_df = pd.concat([model_df, not_in_preds_df], axis=1)\n","    \n","    # fill the nan values with 0\n","    new_model_df = new_model_df.fillna(0)\n","    \n","    # keep track of the row_id order for later\n","    row_id_df = new_model_df[['row_id']]\n","\n","    # filter the new_model_df to only include the columns in pred_cols with the correct order\n","    return new_model_df[train_cols], row_id_df"]},{"cell_type":"markdown","id":"f11d5b18","metadata":{"papermill":{"duration":0.004462,"end_time":"2023-04-28T05:08:57.74682","exception":false,"start_time":"2023-04-28T05:08:57.742358","status":"completed"},"tags":[]},"source":["## Train the models for Visit 0 and the Forecasting\n"]},{"cell_type":"code","execution_count":9,"id":"841e2fbb","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:08:57.757582Z","iopub.status.busy":"2023-04-28T05:08:57.756936Z","iopub.status.idle":"2023-04-28T05:12:59.745592Z","shell.execute_reply":"2023-04-28T05:12:59.744022Z"},"papermill":{"duration":241.99661,"end_time":"2023-04-28T05:12:59.748081","exception":false,"start_time":"2023-04-28T05:08:57.751471","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["SMAPE = 36.99, R2 = 0.882756818063978, MAPE = 577624603892519.5\n","SMAPE = 67.52, R2 = 0.8889851656422887, MAPE = 1979939263145383.2\n","SMAPE = 58.76, R2 = 0.8979083351951844, MAPE = 4100148613493203.5\n","SMAPE = 129.79, R2 = 0.8688203953747919, MAPE = 1931798877069098.2\n","updrs_1 6 SMAPE: 37.93\n","updrs_1 12 SMAPE: 35.55\n","updrs_1 24 SMAPE: 35.17\n","updrs_2 6 SMAPE: 22.58\n","updrs_2 12 SMAPE: 67.7\n","updrs_2 24 SMAPE: 70.08\n","updrs_3 6 SMAPE: 21.06\n","updrs_3 12 SMAPE: 47.96\n","updrs_3 24 SMAPE: 53.01\n","updrs_4 6 forecasting model failed!!!!!\n","updrs_4 12 SMAPE: 127.5\n","updrs_4 24 SMAPE: 113.38\n"]}],"source":["# read the training data with folds\n","train_df = pd.read_csv('/kaggle/input/amp-pd/train_clinical_data.csv')\n","train_prot_df = pd.read_csv('/kaggle/input/amp-pd/train_proteins.csv')\n","train_pep_df = pd.read_csv('/kaggle/input/amp-pd/train_peptides.csv')\n","\n","train_df_dict = preprocess_train_df(train_df, train_prot_df, train_pep_df)\n","\n","    \n","trained_models_dict, visit0_col_dict = train_rf_model(train_df_dict)\n","    \n","\n","processed_forecast_dict = dict()\n","\n","for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n","    \n","    forecast_data = train_df_dict[updr]\n","    processed_forecast_dict[updr] = preprocess_forecast_train_df(forecast_data, updr)\n","    \n","    \n","    \n","    \n","forecast_col_dict = {'updrs_1':{6:_, 12:_, 24:_}, 'updrs_2':{6:_, 12:_, 24:_}, 'updrs_3':{6:_, 12:_, 24:_}, 'updrs_4':{6:_, 12:_, 24:_}}\n","\n","model_1_6, model_1_12, model_1_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n","model_2_6, model_2_12, model_2_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n","model_3_6, model_3_12, model_3_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n","model_4_6, model_4_12, model_4_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n","\n","# store the instantiated models\n","forecast_dict = {'updrs_1':{6:model_1_6, 12:model_1_12, 24:model_1_24},\n","                 'updrs_2':{6:model_2_6, 12:model_2_12, 24:model_2_24},\n","                 'updrs_3':{6:model_3_6, 12:model_3_12, 24:model_3_24},\n","                 'updrs_4':{6:model_4_6, 12:model_4_12, 24:model_4_24}}\n","\n","\n","for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n","    for month_diff in [6, 12, 24]:\n","        \n","        try:\n","            forecast_model, forecast_cols = train_forecast(forecast_dict[updr][month_diff], processed_forecast_dict, updr, month_diff)\n","            forecast_dict[updr][month_diff] = forecast_model\n","            forecast_col_dict[updr][month_diff] = forecast_cols\n","        except:\n","            print(f'{updr} {month_diff} forecasting model failed!!!!!')\n","            \n","            \n"]},{"cell_type":"code","execution_count":10,"id":"ece07291","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:12:59.76187Z","iopub.status.busy":"2023-04-28T05:12:59.760952Z","iopub.status.idle":"2023-04-28T05:12:59.76723Z","shell.execute_reply":"2023-04-28T05:12:59.766332Z"},"papermill":{"duration":0.015049,"end_time":"2023-04-28T05:12:59.769317","exception":false,"start_time":"2023-04-28T05:12:59.754268","status":"completed"},"tags":[]},"outputs":[],"source":["def fill_test_cols(test_df, pred_cols):\n","    '''\n","        Takes in the prediction columns and the test dataframe\n","        Returns the dataframe with all of the necessary columns for prediction\n","    '''\n","    # get the missing columns need for prediction\n","    missing_cols_from_test = [col for col in pred_cols if col not in test_df.columns]\n","\n","    # create a dataframe with those columns\n","    missing_cols_df = pd.DataFrame(columns = missing_cols_from_test)\n","\n","    # concat these columns to the test_df\n","    test_df = pd.concat([test_df, missing_cols_df], axis=1)\n","\n","    # fill the na with 0\n","    test_df = test_df.fillna(0)\n","\n","    return test_df[pred_cols]"]},{"cell_type":"markdown","id":"11ab6801","metadata":{"papermill":{"duration":0.005017,"end_time":"2023-04-28T05:12:59.779674","exception":false,"start_time":"2023-04-28T05:12:59.774657","status":"completed"},"tags":[]},"source":["## Create the Prediction Function"]},{"cell_type":"code","execution_count":11,"id":"d180dde8","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:12:59.791707Z","iopub.status.busy":"2023-04-28T05:12:59.791422Z","iopub.status.idle":"2023-04-28T05:12:59.807049Z","shell.execute_reply":"2023-04-28T05:12:59.805943Z"},"papermill":{"duration":0.024317,"end_time":"2023-04-28T05:12:59.809347","exception":false,"start_time":"2023-04-28T05:12:59.78503","status":"completed"},"tags":[]},"outputs":[],"source":["def create_submission(test_df, test_prot_df, test_pep_df, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict):\n","\n","    '''\n","    Need to input the following variables:\n","\n","    test_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test.csv')\n","    test_prot_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_proteins.csv')\n","    test_pep_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_peptides.csv')\n","    visit0_col_dict\n","    trained_models_dict\n","    forecast_col_dict\n","    forecast_dict\n","    '''\n","    test_preprocessed_df = preprocess_test_df(test_df, test_prot_df, test_pep_df)\n","\n","\n","\n","    visit0_df = pd.DataFrame()\n","\n","\n","    final_df = pd.DataFrame()\n","\n","    # for visit 0\n","    for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n","    \n","        # predict the 0 visit first\n","    \n","        md_df, row_id = prepare_model_df(test_preprocessed_df, updr, visit0_col_dict[updr], visit_month=0)\n","        md_df = fill_test_cols(md_df, visit0_col_dict[updr])\n","        trained_model = trained_models_dict[updr]\n","        preds = trained_model.predict(md_df.values)\n","        row_id[f'{updr}'] = preds\n","        temp_df = pd.concat([row_id, md_df], axis=1)\n","        visit0_df = pd.concat([visit0_df, temp_df])\n","\n","        for month in [6, 12, 24]:\n","            if updr == 'updrs_4' and month == 6:\n","                # split the difference between 0 and 12\n","                forecast_cols = forecast_col_dict[updr][12]\n","                forecast_df = visit0_df.dropna(subset=[updr])\n","                forecast_id = forecast_df['row_id']\n","                forecast_df = fill_test_cols(forecast_df, forecast_cols)\n","                \n","    \n","                # get the forecast model\n","                forecast_model = forecast_dict[updr][12]\n","                preds = forecast_model.predict(forecast_df.values)\n","                visit0_preds = forecast_df['updrs_4']\n","                impute_preds = (preds + visit0_preds) / 2\n","                forecast_df[f'{updr}_{month}'] = impute_preds\n","                visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n","            \n","            else:\n","                # predict the 6, 12, and 24 later visits\n","                forecast_cols = forecast_col_dict[updr][month]\n","                forecast_df = visit0_df.dropna(subset=[updr])\n","                forecast_id = forecast_df['row_id']\n","                forecast_df = fill_test_cols(forecast_df, forecast_cols)\n","    \n","                # get the forecast model\n","                forecast_model = forecast_dict[updr][month]\n","                preds = forecast_model.predict(forecast_df.values)\n","                forecast_df[f'{updr}_{month}'] = preds\n","                visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n","            \n","        final_df = pd.concat([final_df, visit0_df])\n","        final_df = final_df.drop_duplicates()\n","            \n","    pred_df = final_df[[col for col in final_df.columns if col == 'row_id' or col[:5] == 'updrs']]\n","\n","    melted_df = pd.melt(pred_df, id_vars=['row_id'], value_vars=pred_df.columns[1:])\n","    melted_df = melted_df.dropna()\n","\n","    for i, row in melted_df.iterrows():\n","        if row['variable'] in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n","            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_0_months'\n","        elif row['variable'] in ['updrs_1_6', 'updrs_2_6', 'updrs_3_6', 'updrs_4_6']:\n","            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_6_months'\n","        elif row['variable'] in ['updrs_1_12', 'updrs_2_12', 'updrs_3_12', 'updrs_4_12']:\n","            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_12_months'\n","        else:\n","            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_24_months'\n","        \n","    melted_df = melted_df.rename(columns={'value':'rating'}).drop(columns=['variable'])\n","    result = melted_df.reset_index(drop=True)\n","    result = result.rename(columns={'row_id':'prediction_id'})\n","    \n","    return result"]},{"cell_type":"code","execution_count":12,"id":"43ac5371","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:12:59.821027Z","iopub.status.busy":"2023-04-28T05:12:59.82074Z","iopub.status.idle":"2023-04-28T05:12:59.847289Z","shell.execute_reply":"2023-04-28T05:12:59.846287Z"},"papermill":{"duration":0.034594,"end_time":"2023-04-28T05:12:59.849367","exception":false,"start_time":"2023-04-28T05:12:59.814773","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prediction_id</th>\n","      <th>rating</th>\n","      <th>group_key</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3342_0_updrs_1_plus_0_months</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3342_0_updrs_1_plus_6_months</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3342_0_updrs_1_plus_12_months</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3342_0_updrs_1_plus_24_months</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3342_0_updrs_2_plus_0_months</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>50423_6_updrs_3_plus_24_months</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>50423_6_updrs_4_plus_0_months</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>50423_6_updrs_4_plus_6_months</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>50423_6_updrs_4_plus_12_months</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>50423_6_updrs_4_plus_24_months</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>64 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                     prediction_id  rating  group_key\n","0     3342_0_updrs_1_plus_0_months       0          0\n","1     3342_0_updrs_1_plus_6_months       0          0\n","2    3342_0_updrs_1_plus_12_months       0          0\n","3    3342_0_updrs_1_plus_24_months       0          0\n","4     3342_0_updrs_2_plus_0_months       0          0\n","..                             ...     ...        ...\n","59  50423_6_updrs_3_plus_24_months       0          6\n","60   50423_6_updrs_4_plus_0_months       0          6\n","61   50423_6_updrs_4_plus_6_months       0          6\n","62  50423_6_updrs_4_plus_12_months       0          6\n","63  50423_6_updrs_4_plus_24_months       0          6\n","\n","[64 rows x 3 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["sample = pd.read_csv('/kaggle/input/amp-pd/example_test_files/sample_submission.csv')\n","sample"]},{"cell_type":"code","execution_count":13,"id":"01c7dfb9","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:12:59.862316Z","iopub.status.busy":"2023-04-28T05:12:59.861311Z","iopub.status.idle":"2023-04-28T05:13:00.858527Z","shell.execute_reply":"2023-04-28T05:13:00.857512Z"},"papermill":{"duration":1.006065,"end_time":"2023-04-28T05:13:00.861133","exception":false,"start_time":"2023-04-28T05:12:59.855068","status":"completed"},"tags":[]},"outputs":[],"source":["test = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test.csv')\n","test_proteins = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_proteins.csv')\n","test_peptides = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_peptides.csv')\n","result = create_submission(test, test_proteins, test_peptides, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict)\n"]},{"cell_type":"code","execution_count":14,"id":"5b349b81","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:13:00.876981Z","iopub.status.busy":"2023-04-28T05:13:00.876673Z","iopub.status.idle":"2023-04-28T05:13:00.893135Z","shell.execute_reply":"2023-04-28T05:13:00.892248Z"},"papermill":{"duration":0.026476,"end_time":"2023-04-28T05:13:00.895336","exception":false,"start_time":"2023-04-28T05:13:00.86886","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prediction_id</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>3342_0_updrs_1_plus_0_months</td>\n","      <td>6.420</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>3342_0_updrs_1_plus_12_months</td>\n","      <td>6.020</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>3342_0_updrs_1_plus_24_months</td>\n","      <td>6.250</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3342_0_updrs_1_plus_6_months</td>\n","      <td>6.930</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>3342_0_updrs_2_plus_0_months</td>\n","      <td>4.910</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>3342_0_updrs_2_plus_12_months</td>\n","      <td>6.610</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>3342_0_updrs_2_plus_24_months</td>\n","      <td>6.650</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>3342_0_updrs_2_plus_6_months</td>\n","      <td>6.180</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>3342_0_updrs_3_plus_0_months</td>\n","      <td>18.020</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>3342_0_updrs_3_plus_12_months</td>\n","      <td>20.790</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>3342_0_updrs_3_plus_24_months</td>\n","      <td>20.330</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>3342_0_updrs_3_plus_6_months</td>\n","      <td>17.620</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>3342_0_updrs_4_plus_0_months</td>\n","      <td>2.090</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>3342_0_updrs_4_plus_12_months</td>\n","      <td>0.920</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>3342_0_updrs_4_plus_24_months</td>\n","      <td>1.230</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>3342_0_updrs_4_plus_6_months</td>\n","      <td>1.505</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3342_6_updrs_1_plus_0_months</td>\n","      <td>6.420</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3342_6_updrs_1_plus_12_months</td>\n","      <td>6.020</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>3342_6_updrs_1_plus_24_months</td>\n","      <td>6.250</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3342_6_updrs_1_plus_6_months</td>\n","      <td>6.930</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>3342_6_updrs_2_plus_0_months</td>\n","      <td>4.910</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>3342_6_updrs_2_plus_12_months</td>\n","      <td>6.610</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>3342_6_updrs_2_plus_24_months</td>\n","      <td>6.650</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>3342_6_updrs_2_plus_6_months</td>\n","      <td>6.180</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>3342_6_updrs_3_plus_0_months</td>\n","      <td>18.020</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>3342_6_updrs_3_plus_12_months</td>\n","      <td>20.790</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>3342_6_updrs_3_plus_24_months</td>\n","      <td>20.330</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>3342_6_updrs_3_plus_6_months</td>\n","      <td>17.620</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>3342_6_updrs_4_plus_0_months</td>\n","      <td>2.090</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>3342_6_updrs_4_plus_12_months</td>\n","      <td>0.920</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>3342_6_updrs_4_plus_24_months</td>\n","      <td>1.230</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>3342_6_updrs_4_plus_6_months</td>\n","      <td>1.505</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>50423_0_updrs_1_plus_0_months</td>\n","      <td>7.120</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>50423_0_updrs_1_plus_12_months</td>\n","      <td>8.760</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>50423_0_updrs_1_plus_24_months</td>\n","      <td>8.260</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50423_0_updrs_1_plus_6_months</td>\n","      <td>9.310</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>50423_0_updrs_2_plus_0_months</td>\n","      <td>8.940</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>50423_0_updrs_2_plus_12_months</td>\n","      <td>9.780</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>50423_0_updrs_2_plus_24_months</td>\n","      <td>10.320</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>50423_0_updrs_2_plus_6_months</td>\n","      <td>9.500</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>50423_0_updrs_3_plus_0_months</td>\n","      <td>18.340</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>50423_0_updrs_3_plus_12_months</td>\n","      <td>22.230</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>50423_0_updrs_3_plus_24_months</td>\n","      <td>22.040</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>50423_0_updrs_3_plus_6_months</td>\n","      <td>21.470</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>50423_0_updrs_4_plus_0_months</td>\n","      <td>2.700</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>50423_0_updrs_4_plus_12_months</td>\n","      <td>1.940</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>50423_0_updrs_4_plus_24_months</td>\n","      <td>2.920</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>50423_0_updrs_4_plus_6_months</td>\n","      <td>2.320</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50423_6_updrs_1_plus_0_months</td>\n","      <td>7.120</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>50423_6_updrs_1_plus_12_months</td>\n","      <td>8.760</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>50423_6_updrs_1_plus_24_months</td>\n","      <td>8.260</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>50423_6_updrs_1_plus_6_months</td>\n","      <td>9.310</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>50423_6_updrs_2_plus_0_months</td>\n","      <td>8.940</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>50423_6_updrs_2_plus_12_months</td>\n","      <td>9.780</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>50423_6_updrs_2_plus_24_months</td>\n","      <td>10.320</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>50423_6_updrs_2_plus_6_months</td>\n","      <td>9.500</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>50423_6_updrs_3_plus_0_months</td>\n","      <td>18.340</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>50423_6_updrs_3_plus_12_months</td>\n","      <td>22.230</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>50423_6_updrs_3_plus_24_months</td>\n","      <td>22.040</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>50423_6_updrs_3_plus_6_months</td>\n","      <td>21.470</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>50423_6_updrs_4_plus_0_months</td>\n","      <td>2.700</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>50423_6_updrs_4_plus_12_months</td>\n","      <td>1.940</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>50423_6_updrs_4_plus_24_months</td>\n","      <td>2.920</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>50423_6_updrs_4_plus_6_months</td>\n","      <td>2.320</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     prediction_id  rating\n","2     3342_0_updrs_1_plus_0_months   6.420\n","10   3342_0_updrs_1_plus_12_months   6.020\n","14   3342_0_updrs_1_plus_24_months   6.250\n","6     3342_0_updrs_1_plus_6_months   6.930\n","18    3342_0_updrs_2_plus_0_months   4.910\n","26   3342_0_updrs_2_plus_12_months   6.610\n","30   3342_0_updrs_2_plus_24_months   6.650\n","22    3342_0_updrs_2_plus_6_months   6.180\n","34    3342_0_updrs_3_plus_0_months  18.020\n","42   3342_0_updrs_3_plus_12_months  20.790\n","46   3342_0_updrs_3_plus_24_months  20.330\n","38    3342_0_updrs_3_plus_6_months  17.620\n","50    3342_0_updrs_4_plus_0_months   2.090\n","58   3342_0_updrs_4_plus_12_months   0.920\n","62   3342_0_updrs_4_plus_24_months   1.230\n","54    3342_0_updrs_4_plus_6_months   1.505\n","1     3342_6_updrs_1_plus_0_months   6.420\n","9    3342_6_updrs_1_plus_12_months   6.020\n","13   3342_6_updrs_1_plus_24_months   6.250\n","5     3342_6_updrs_1_plus_6_months   6.930\n","17    3342_6_updrs_2_plus_0_months   4.910\n","25   3342_6_updrs_2_plus_12_months   6.610\n","29   3342_6_updrs_2_plus_24_months   6.650\n","21    3342_6_updrs_2_plus_6_months   6.180\n","32    3342_6_updrs_3_plus_0_months  18.020\n","40   3342_6_updrs_3_plus_12_months  20.790\n","44   3342_6_updrs_3_plus_24_months  20.330\n","36    3342_6_updrs_3_plus_6_months  17.620\n","49    3342_6_updrs_4_plus_0_months   2.090\n","57   3342_6_updrs_4_plus_12_months   0.920\n","61   3342_6_updrs_4_plus_24_months   1.230\n","53    3342_6_updrs_4_plus_6_months   1.505\n","0    50423_0_updrs_1_plus_0_months   7.120\n","8   50423_0_updrs_1_plus_12_months   8.760\n","12  50423_0_updrs_1_plus_24_months   8.260\n","4    50423_0_updrs_1_plus_6_months   9.310\n","16   50423_0_updrs_2_plus_0_months   8.940\n","24  50423_0_updrs_2_plus_12_months   9.780\n","28  50423_0_updrs_2_plus_24_months  10.320\n","20   50423_0_updrs_2_plus_6_months   9.500\n","33   50423_0_updrs_3_plus_0_months  18.340\n","41  50423_0_updrs_3_plus_12_months  22.230\n","45  50423_0_updrs_3_plus_24_months  22.040\n","37   50423_0_updrs_3_plus_6_months  21.470\n","48   50423_0_updrs_4_plus_0_months   2.700\n","56  50423_0_updrs_4_plus_12_months   1.940\n","60  50423_0_updrs_4_plus_24_months   2.920\n","52   50423_0_updrs_4_plus_6_months   2.320\n","3    50423_6_updrs_1_plus_0_months   7.120\n","11  50423_6_updrs_1_plus_12_months   8.760\n","15  50423_6_updrs_1_plus_24_months   8.260\n","7    50423_6_updrs_1_plus_6_months   9.310\n","19   50423_6_updrs_2_plus_0_months   8.940\n","27  50423_6_updrs_2_plus_12_months   9.780\n","31  50423_6_updrs_2_plus_24_months  10.320\n","23   50423_6_updrs_2_plus_6_months   9.500\n","35   50423_6_updrs_3_plus_0_months  18.340\n","43  50423_6_updrs_3_plus_12_months  22.230\n","47  50423_6_updrs_3_plus_24_months  22.040\n","39   50423_6_updrs_3_plus_6_months  21.470\n","51   50423_6_updrs_4_plus_0_months   2.700\n","59  50423_6_updrs_4_plus_12_months   1.940\n","63  50423_6_updrs_4_plus_24_months   2.920\n","55   50423_6_updrs_4_plus_6_months   2.320"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["pd.set_option('display.max_rows', None)\n","result.sort_values(by='prediction_id')"]},{"cell_type":"markdown","id":"3c14fb44","metadata":{"papermill":{"duration":0.005681,"end_time":"2023-04-28T05:13:00.907069","exception":false,"start_time":"2023-04-28T05:13:00.901388","status":"completed"},"tags":[]},"source":["## Submission Through the API"]},{"cell_type":"code","execution_count":15,"id":"158cdeec","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:13:00.920212Z","iopub.status.busy":"2023-04-28T05:13:00.91995Z","iopub.status.idle":"2023-04-28T05:13:00.924755Z","shell.execute_reply":"2023-04-28T05:13:00.923573Z"},"papermill":{"duration":0.013801,"end_time":"2023-04-28T05:13:00.926989","exception":false,"start_time":"2023-04-28T05:13:00.913188","status":"completed"},"tags":[]},"outputs":[],"source":["env = amp_pd_peptide.make_env()   # initialize the environment\n","iter_test = env.iter_test()  "]},{"cell_type":"code","execution_count":16,"id":"a395894c","metadata":{"execution":{"iopub.execute_input":"2023-04-28T05:13:00.940306Z","iopub.status.busy":"2023-04-28T05:13:00.940032Z","iopub.status.idle":"2023-04-28T05:13:03.432907Z","shell.execute_reply":"2023-04-28T05:13:03.431865Z"},"papermill":{"duration":2.502454,"end_time":"2023-04-28T05:13:03.435466","exception":false,"start_time":"2023-04-28T05:13:00.933012","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"]}],"source":["for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n","        \n","    result = create_submission(test, test_proteins, test_peptides, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict)\n","\n","    env.predict(result)   # register your predictions\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":256.116774,"end_time":"2023-04-28T05:13:03.961767","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-04-28T05:08:47.844993","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}