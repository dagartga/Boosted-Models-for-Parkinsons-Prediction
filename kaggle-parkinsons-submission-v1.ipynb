{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/dagartallison/parkinsons-submission-v1?scriptVersionId=127742339\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:40.36728Z",
     "iopub.status.busy": "2023-04-30T01:14:40.366354Z",
     "iopub.status.idle": "2023-04-30T01:14:40.42859Z",
     "shell.execute_reply": "2023-04-30T01:14:40.427654Z",
     "shell.execute_reply.started": "2023-04-30T01:14:40.367165Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/amp-pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:40.431298Z",
     "iopub.status.busy": "2023-04-30T01:14:40.430844Z",
     "iopub.status.idle": "2023-04-30T01:14:41.341959Z",
     "shell.execute_reply": "2023-04-30T01:14:41.340977Z",
     "shell.execute_reply.started": "2023-04-30T01:14:40.431256Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import amp_pd_peptide\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:41.343861Z",
     "iopub.status.busy": "2023-04-30T01:14:41.343496Z",
     "iopub.status.idle": "2023-04-30T01:14:41.356254Z",
     "shell.execute_reply": "2023-04-30T01:14:41.355309Z",
     "shell.execute_reply.started": "2023-04-30T01:14:41.343823Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_train_df(train_clin_df, train_prot_df, train_pep_df):\n",
    "    '''\n",
    "        Takes in the train_clinical_data.csv, train_peptides.csv, train_proteins.csv as pandas dataframes\n",
    "        Combines the protein and peptide data names and the joins with the train clinical data\n",
    "        The dataframes are stratified kfold based on the target\n",
    "        The function creates one dataframe for each target (updrs_1, updrs_2, updrs_3, updrs_4) stored in the final_df dictionary\n",
    "        Returns a dictionary of the dataframes for each updrs target\n",
    "    '''\n",
    "    \n",
    "    # drop the medication column\n",
    "    train_clin_df = train_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n",
    "    \n",
    "    # create a column with the UniProt and Peptide name combined\n",
    "    train_pep_df['peptide_uniprot'] = train_pep_df['Peptide'] + '_'+ train_pep_df['UniProt']\n",
    "\n",
    "    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n",
    "    train_prot_pivot = train_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n",
    "    train_pep_pivot = train_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n",
    "\n",
    "    # combine the two tables on the visit_id\n",
    "    full_prot_train_df = train_prot_pivot.join(train_pep_pivot)\n",
    "\n",
    "    # fill nan with 0 for this first round\n",
    "    full_prot_train_df = full_prot_train_df.fillna(0)\n",
    "\n",
    "    full_train_df = train_clin_df.merge(full_prot_train_df, how='inner', left_on='visit_id', right_on='visit_id')\n",
    "    full_train_df = full_train_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    updrs = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n",
    "\n",
    "    final_dfs = dict()\n",
    "\n",
    "    for target in updrs:\n",
    "    \n",
    "        to_remove = [updr for updr in updrs if updr != target]\n",
    "        \n",
    "        temp_train_df = full_train_df.drop(to_remove, axis=1)\n",
    "        temp_train_df = temp_train_df.dropna()\n",
    "        \n",
    "        # calculate the number of bins by Sturge's rule\n",
    "        num_bins = int(np.floor(1 + np.log2(len(full_train_df))))\n",
    "        temp_train_df.loc[:, \"bins\"] = pd.cut(temp_train_df[target], bins=num_bins, labels=False)\n",
    "\n",
    "        temp_train_df = temp_train_df.dropna().reset_index(drop=True)\n",
    "        \n",
    "        # initiate the kfold class from sklearn\n",
    "        kf = StratifiedKFold(n_splits=5)\n",
    "        \n",
    "        # create a kfold column\n",
    "        temp_train_df['kfold'] = -1\n",
    "\n",
    "        # fill the kfold column\n",
    "        for f, (t_, v_) in enumerate(kf.split(X=temp_train_df, y=temp_train_df['bins'].values)):\n",
    "            temp_train_df.loc[v_, 'kfold'] = f\n",
    "            \n",
    "        # drop the bins column\n",
    "        temp_train_df = temp_train_df.drop('bins', axis=1)\n",
    "        \n",
    "     \n",
    "\n",
    "        final_dfs[target] = temp_train_df\n",
    "            \n",
    "    return final_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:41.360256Z",
     "iopub.status.busy": "2023-04-30T01:14:41.359542Z",
     "iopub.status.idle": "2023-04-30T01:14:41.375953Z",
     "shell.execute_reply": "2023-04-30T01:14:41.375054Z",
     "shell.execute_reply.started": "2023-04-30T01:14:41.36022Z"
    }
   },
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "\n",
    "    return round(np.mean(np.abs(y_pred - y_true) / ((np.abs(y_true) + np.abs(y_pred))/2)) * 100, 2)\n",
    "\n",
    "\n",
    "\n",
    "def train_rf_model(df_dict):\n",
    "    '''\n",
    "        Takes in the preprocesses training dictionary of dataframes \n",
    "        Then trains a random forest regressor model on the data\n",
    "        Returns a dictionary of models, one for each updrs target\n",
    "    '''\n",
    "    model_dict = {}\n",
    "    visit0_col_dict = {}\n",
    "    \n",
    "    updr1_model = RandomForestRegressor(random_state = 42)\n",
    "    updr2_model = RandomForestRegressor(random_state = 42)\n",
    "    updr3_model = RandomForestRegressor(random_state = 42)\n",
    "    updr4_model = RandomForestRegressor(random_state = 42)\n",
    "    \n",
    "    for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n",
    "        df = df_dict[updr]\n",
    "        df = df.drop(columns=['visit_id', 'patient_id', 'kfold'])\n",
    "\n",
    "        y_train = df[updr].values\n",
    "        df = df.drop(columns=[updr])\n",
    "        x_train = df.values\n",
    "\n",
    "        \n",
    "        if updr == 'updrs_1':\n",
    "            updr1_model.fit(x_train, y_train)\n",
    "            preds = updr1_model.predict(x_train)\n",
    "            r2 = metrics.r2_score(y_train, preds)\n",
    "            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n",
    "            s_mape = smape(y_train, preds)\n",
    "            model_dict[updr] = updr1_model\n",
    "            visit0_col_dict[updr] = df.columns\n",
    "            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n",
    "\n",
    "        elif updr == 'updrs_2':\n",
    "            updr2_model.fit(x_train, y_train)\n",
    "            preds = updr2_model.predict(x_train)\n",
    "            r2 = metrics.r2_score(y_train, preds)\n",
    "            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n",
    "            s_mape = smape(y_train, preds)\n",
    "            model_dict[updr] = updr2_model\n",
    "            visit0_col_dict[updr] = df.columns\n",
    "            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n",
    "\n",
    "        elif updr == 'updrs_3':\n",
    "            updr3_model.fit(x_train, y_train)\n",
    "            preds = updr3_model.predict(x_train)\n",
    "            r2 = metrics.r2_score(y_train, preds)\n",
    "            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n",
    "            s_mape = smape(y_train, preds)\n",
    "            model_dict[updr] = updr3_model\n",
    "            visit0_col_dict[updr] = df.columns\n",
    "            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n",
    "        else:\n",
    "            updr4_model.fit(x_train, y_train)\n",
    "            preds = updr4_model.predict(x_train)\n",
    "            r2 = metrics.r2_score(y_train, preds)\n",
    "            mape = metrics.mean_absolute_percentage_error(y_train, preds)\n",
    "            s_mape = smape(y_train, preds)\n",
    "            model_dict[updr] = updr4_model\n",
    "            visit0_col_dict[updr] = df.columns\n",
    "            print(f'SMAPE = {s_mape}, R2 = {r2}, MAPE = {mape}')\n",
    "        \n",
    "    \n",
    "    return model_dict, visit0_col_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model for Forecasting the future months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:41.377245Z",
     "iopub.status.busy": "2023-04-30T01:14:41.37693Z",
     "iopub.status.idle": "2023-04-30T01:14:41.393241Z",
     "shell.execute_reply": "2023-04-30T01:14:41.39229Z",
     "shell.execute_reply.started": "2023-04-30T01:14:41.377218Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_forecast_train_df(preprocessed_train_df, target):\n",
    "    '''\n",
    "        Takes in the preprocessed training dataframe for a single updrs\n",
    "        Returns a dataframe for forecasting which has columns for the updrs of different future visits\n",
    "    '''\n",
    "    \n",
    "    temp_df = preprocessed_train_df[['visit_id', 'patient_id', target, 'visit_month']].sort_values(by=['patient_id', 'visit_month']).reset_index(drop=True)\n",
    "    temp_pivot = temp_df.pivot(columns='visit_month', values=target, index='patient_id')\n",
    "    temp_pivot = temp_pivot.reset_index()\n",
    "    \n",
    "    cols = [f'{target}_{month}' for month in temp_pivot.columns[1:]]\n",
    "    temp_pivot.columns = ['patient_id'] + cols\n",
    "    \n",
    "    forecast_final = preprocessed_train_df[preprocessed_train_df['visit_month'] == 0]\n",
    "    \n",
    "    final_df = forecast_final.merge(temp_pivot, on=['patient_id'], how='left')\n",
    "    \n",
    "    final_df = final_df.drop(columns=['patient_id', target])\n",
    "    if 'kfold' in final_df.columns:\n",
    "        final_df = final_df.drop(columns=['kfold'])\n",
    "        \n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the forecasting dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:41.396665Z",
     "iopub.status.busy": "2023-04-30T01:14:41.396355Z",
     "iopub.status.idle": "2023-04-30T01:14:41.415686Z",
     "shell.execute_reply": "2023-04-30T01:14:41.413864Z",
     "shell.execute_reply.started": "2023-04-30T01:14:41.396634Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_forecast(model, processed_forecast_dict, target, month_diff):\n",
    "    \n",
    "    # results dictionary for the models\n",
    "    forecast_model_dict = dict()\n",
    "    \n",
    "    # get the training dataset\n",
    "    df = processed_forecast_dict[target]\n",
    "    \n",
    "    forecast_cols = [col for col in df.columns if 'updrs' in col]\n",
    "\n",
    "    drop_cols = [col for col in forecast_cols if col not in  [f'{target}_0', f'{target}_{month_diff}']]\n",
    "\n",
    "    df = df.drop(columns=drop_cols)\n",
    "    df = df.drop(columns=['visit_id', 'visit_month'])\n",
    "    df = df.rename(columns={f'{target}_0': target})\n",
    "    \n",
    "    target_mo = f'{target}_{month_diff}'\n",
    "    # drop nan rows for target column\n",
    "    df = df.dropna(subset=[target_mo])\n",
    "    \n",
    "    X, y = df, df[target_mo]\n",
    "    \n",
    "    X = X.drop([target_mo], axis=1).values\n",
    "    \n",
    "\n",
    "    reg = model\n",
    "    reg.fit(X, y)\n",
    "    preds = reg.predict(X)\n",
    "    \n",
    "    r2 = metrics.r2_score(y, preds)\n",
    "    mape = metrics.mean_absolute_percentage_error(y, preds)\n",
    "    s_mape = smape(y, preds)\n",
    "    \n",
    "    print(target, month_diff, 'SMAPE:', s_mape)\n",
    "    \n",
    "    return model, df.drop(columns=target_mo).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:41.419793Z",
     "iopub.status.busy": "2023-04-30T01:14:41.418479Z",
     "iopub.status.idle": "2023-04-30T01:14:41.446094Z",
     "shell.execute_reply": "2023-04-30T01:14:41.445109Z",
     "shell.execute_reply.started": "2023-04-30T01:14:41.419748Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_test_df(test_clin_df, test_prot_df, test_pep_df):\n",
    "    '''\n",
    "        Takes in the test data from the csv file in the form of a pandas dataframe\n",
    "        Combines the peptide and protein data\n",
    "        Outputs the dataframe for inference\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if 'upd23b_clinical_state_on_medication' in test_clin_df.columns:\n",
    "        # drop the medication column\n",
    "        test_clin_df = test_clin_df.drop(columns=['upd23b_clinical_state_on_medication'])\n",
    "    \n",
    "    if 'group_key' in test_clin_df.columns:\n",
    "        # drop the group key\n",
    "        test_clin_df = test_clin_df.drop(columns=['group_key'])\n",
    "    \n",
    "    # create a column with the UniProt and Peptide name combined\n",
    "    test_pep_df['peptide_uniprot'] = test_pep_df['Peptide'] + '_'+ test_pep_df['UniProt']\n",
    "\n",
    "    # create a table with the visit_id as the index and the proteins or peptides as the feature and the abundance as the values\n",
    "    test_prot_pivot = test_prot_df.pivot(index='visit_id', values='NPX', columns='UniProt')\n",
    "    test_pep_pivot = test_pep_df.pivot(index='visit_id', values='PeptideAbundance', columns='peptide_uniprot')\n",
    "\n",
    "    # combine the two tables on the visit_id\n",
    "    full_prot_test_df = test_prot_pivot.join(test_pep_pivot)\n",
    "\n",
    "    # fill nan with 0 \n",
    "    full_prot_test_df = full_prot_test_df.fillna(0)\n",
    "\n",
    "    full_test_df = test_clin_df.merge(full_prot_test_df, how='inner', left_on='visit_id', right_on='visit_id')\n",
    "    full_test_df = full_test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    missing_row_id = [x for x in test_clin_df['row_id'] if x not in full_test_df['row_id'].to_list()]\n",
    "    filtered_df = test_clin_df[test_clin_df['row_id'].isin(missing_row_id)]\n",
    "    imputed_df = filtered_df.drop(columns=['visit_month']).merge(full_test_df.drop(columns=['row_id', 'visit_id']),\n",
    "                                                                    how='left', \n",
    "                                                                    left_on=['patient_id', 'updrs_test'],\n",
    "                                                                    right_on=['patient_id', 'updrs_test'])\n",
    "    full_test_df = pd.concat([full_test_df, imputed_df])\n",
    "    \n",
    "    full_test_df = full_test_df.reset_index(drop=True)\n",
    "    \n",
    "    # remove the imputed visit month and replace from the test df\n",
    "    full_test_df = full_test_df.drop(columns='visit_month').merge(test_clin_df[['row_id', 'visit_month']], how='left', left_on='row_id', right_on='row_id')\n",
    "    \n",
    "    return full_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:41.454346Z",
     "iopub.status.busy": "2023-04-30T01:14:41.451295Z",
     "iopub.status.idle": "2023-04-30T01:14:41.466091Z",
     "shell.execute_reply": "2023-04-30T01:14:41.464982Z",
     "shell.execute_reply.started": "2023-04-30T01:14:41.454306Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_model_df(model_df, target, train_cols, visit_month=0):\n",
    "    '''\n",
    "        model_df is the preprocessed test dataframe which has all of the protein data\n",
    "        target is the updrs number\n",
    "        train_cols are the list of columns necessary for the model to do the inference\n",
    "        visit_month is the month of data we want to filter\n",
    "    '''\n",
    "\n",
    "    # add visit_month if it is not in the model_df.columns\n",
    "    if 'visit_month' not in model_df.columns:\n",
    "        model_df['visit_month'] = visit_month\n",
    "    \n",
    "    # start will all the visit_months as 0 for the first prediction\n",
    "    model_df['visit_month'] = 0\n",
    "    \n",
    "    model_df = model_df[model_df['updrs_test'] == target]\n",
    "    \n",
    "    # find the columns in preds_cols that are not in the model_df.columns\n",
    "    not_in_pred_cols = [col for col in train_cols if col not in model_df.columns]\n",
    "\n",
    "    # create an empty dataframe with the columns in not_in_pred_cols\n",
    "    not_in_preds_df = pd.DataFrame(columns=not_in_pred_cols)\n",
    "\n",
    "    # combine the model_df and the not_in_preds_df so all the needed columns are in dataframe\n",
    "    new_model_df = pd.concat([model_df, not_in_preds_df], axis=1)\n",
    "    \n",
    "    # fill the nan values with 0\n",
    "    new_model_df = new_model_df.fillna(0)\n",
    "    \n",
    "    # keep track of the row_id order for later\n",
    "    row_id_df = new_model_df[['row_id']]\n",
    "\n",
    "    # filter the new_model_df to only include the columns in pred_cols with the correct order\n",
    "    return new_model_df[train_cols], row_id_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models for Visit 0 and the Forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:14:41.468425Z",
     "iopub.status.busy": "2023-04-30T01:14:41.467773Z",
     "iopub.status.idle": "2023-04-30T01:14:44.083774Z",
     "shell.execute_reply": "2023-04-30T01:14:44.082688Z",
     "shell.execute_reply.started": "2023-04-30T01:14:41.468355Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the training data with folds\n",
    "train_df = pd.read_csv('/kaggle/input/amp-pd/train_clinical_data.csv')\n",
    "train_prot_df = pd.read_csv('/kaggle/input/amp-pd/train_proteins.csv')\n",
    "train_pep_df = pd.read_csv('/kaggle/input/amp-pd/train_peptides.csv')\n",
    "\n",
    "train_df_dict = preprocess_train_df(train_df, train_prot_df, train_pep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:23:19.300054Z",
     "iopub.status.busy": "2023-04-30T01:23:19.299701Z",
     "iopub.status.idle": "2023-04-30T01:23:19.307809Z",
     "shell.execute_reply": "2023-04-30T01:23:19.306468Z",
     "shell.execute_reply.started": "2023-04-30T01:23:19.300023Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df_for_visit0(train_df, train_df_dict, updr):\n",
    "    # get the values for visit month 0\n",
    "    visit_month0_df = train_df[train_df['visit_month'] == 0]\n",
    "    visit_month0_df = visit_month0_df.rename(columns={'updrs_1': 'updrs_1_visit_0', 'updrs_2': 'updrs_2_visit_0', 'updrs_3': 'updrs_3_visit_0', 'updrs_4': 'updrs_4_visit_0'})\n",
    "    visit_month0_cols = ['patient_id', f'{updr}_visit_0']\n",
    "    visit_month0_df = visit_month0_df[visit_month0_cols]\n",
    "    train_df_updrs_1 = train_df_dict[updr]\n",
    "    new_train_df = train_df_updrs_1.merge(visit_month0_df, how='left', left_on='patient_id', right_on='patient_id')\n",
    "    new_train_df = new_train_df.drop(columns=[updr])\n",
    "    new_train_df = new_train_df.rename(columns={f'{updr}_visit_0':'updrs_1'})\n",
    "    new_train_df = new_train_df.dropna(subset=[updr])\n",
    "    return new_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-30T01:23:57.503019Z",
     "iopub.status.busy": "2023-04-30T01:23:57.50266Z",
     "iopub.status.idle": "2023-04-30T01:23:57.563944Z",
     "shell.execute_reply": "2023-04-30T01:23:57.562788Z",
     "shell.execute_reply.started": "2023-04-30T01:23:57.50299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visit_month</th>\n",
       "      <th>O00391</th>\n",
       "      <th>O00533</th>\n",
       "      <th>O00584</th>\n",
       "      <th>O14498</th>\n",
       "      <th>O14773</th>\n",
       "      <th>O14791</th>\n",
       "      <th>O15240</th>\n",
       "      <th>...</th>\n",
       "      <th>YVGGQEHFAHLLILR_P02763</th>\n",
       "      <th>YVM(UniMod_35)LPVADQDQC(UniMod_4)IR_P00738</th>\n",
       "      <th>YVMLPVADQDQC(UniMod_4)IR_P00738</th>\n",
       "      <th>YVNKEIQNAVNGVK_P10909</th>\n",
       "      <th>YWGVASFLQK_P02753</th>\n",
       "      <th>YYC(UniMod_4)FQGNQFLR_P02790</th>\n",
       "      <th>YYTYLIMNK_P01024</th>\n",
       "      <th>YYWGGQYTWDMAK_P02675</th>\n",
       "      <th>kfold</th>\n",
       "      <th>updrs_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64674_84</td>\n",
       "      <td>64674</td>\n",
       "      <td>84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>190487.0</td>\n",
       "      <td>24907.9</td>\n",
       "      <td>18543.1</td>\n",
       "      <td>10124.90</td>\n",
       "      <td>2308.71</td>\n",
       "      <td>62095.4</td>\n",
       "      <td>...</td>\n",
       "      <td>4901220.0</td>\n",
       "      <td>40325.90</td>\n",
       "      <td>335625.0</td>\n",
       "      <td>49250.4</td>\n",
       "      <td>64076.3</td>\n",
       "      <td>667993.0</td>\n",
       "      <td>38472.5</td>\n",
       "      <td>21949.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57507_0</td>\n",
       "      <td>57507</td>\n",
       "      <td>0</td>\n",
       "      <td>8283.24</td>\n",
       "      <td>482542.0</td>\n",
       "      <td>36667.9</td>\n",
       "      <td>30565.5</td>\n",
       "      <td>26054.90</td>\n",
       "      <td>1463.14</td>\n",
       "      <td>147160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2761210.0</td>\n",
       "      <td>32719.80</td>\n",
       "      <td>93142.6</td>\n",
       "      <td>68437.4</td>\n",
       "      <td>102022.0</td>\n",
       "      <td>371103.0</td>\n",
       "      <td>30842.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64674_12</td>\n",
       "      <td>64674</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>188974.0</td>\n",
       "      <td>18100.6</td>\n",
       "      <td>16229.9</td>\n",
       "      <td>4728.27</td>\n",
       "      <td>2731.76</td>\n",
       "      <td>26262.9</td>\n",
       "      <td>...</td>\n",
       "      <td>5373440.0</td>\n",
       "      <td>56942.20</td>\n",
       "      <td>400014.0</td>\n",
       "      <td>49278.7</td>\n",
       "      <td>100833.0</td>\n",
       "      <td>599158.0</td>\n",
       "      <td>50942.2</td>\n",
       "      <td>28021.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51708_48</td>\n",
       "      <td>51708</td>\n",
       "      <td>48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>359661.0</td>\n",
       "      <td>26235.8</td>\n",
       "      <td>26673.4</td>\n",
       "      <td>15429.30</td>\n",
       "      <td>3528.49</td>\n",
       "      <td>87260.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2673.08</td>\n",
       "      <td>305865.0</td>\n",
       "      <td>70153.4</td>\n",
       "      <td>107281.0</td>\n",
       "      <td>47861.6</td>\n",
       "      <td>39870.2</td>\n",
       "      <td>32233.2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20352_0</td>\n",
       "      <td>20352</td>\n",
       "      <td>0</td>\n",
       "      <td>11209.50</td>\n",
       "      <td>640924.0</td>\n",
       "      <td>29576.7</td>\n",
       "      <td>29438.1</td>\n",
       "      <td>15884.60</td>\n",
       "      <td>4535.01</td>\n",
       "      <td>206610.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5593620.0</td>\n",
       "      <td>152364.00</td>\n",
       "      <td>2258450.0</td>\n",
       "      <td>104239.0</td>\n",
       "      <td>164414.0</td>\n",
       "      <td>443939.0</td>\n",
       "      <td>63222.0</td>\n",
       "      <td>19664.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>30894_60</td>\n",
       "      <td>30894</td>\n",
       "      <td>60</td>\n",
       "      <td>8024.28</td>\n",
       "      <td>347378.0</td>\n",
       "      <td>28456.3</td>\n",
       "      <td>27444.6</td>\n",
       "      <td>5079.26</td>\n",
       "      <td>2335.54</td>\n",
       "      <td>109329.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33420.00</td>\n",
       "      <td>269386.0</td>\n",
       "      <td>96326.9</td>\n",
       "      <td>131866.0</td>\n",
       "      <td>545595.0</td>\n",
       "      <td>47572.8</td>\n",
       "      <td>40027.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>14035_60</td>\n",
       "      <td>14035</td>\n",
       "      <td>60</td>\n",
       "      <td>7231.95</td>\n",
       "      <td>423538.0</td>\n",
       "      <td>26651.3</td>\n",
       "      <td>17903.3</td>\n",
       "      <td>13334.90</td>\n",
       "      <td>1625.71</td>\n",
       "      <td>129916.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2099330.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>204434.0</td>\n",
       "      <td>74873.4</td>\n",
       "      <td>129314.0</td>\n",
       "      <td>425445.0</td>\n",
       "      <td>43636.3</td>\n",
       "      <td>26534.8</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>59550_60</td>\n",
       "      <td>59550</td>\n",
       "      <td>60</td>\n",
       "      <td>11212.70</td>\n",
       "      <td>451740.0</td>\n",
       "      <td>25389.2</td>\n",
       "      <td>17247.7</td>\n",
       "      <td>9819.39</td>\n",
       "      <td>3405.69</td>\n",
       "      <td>204601.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4659100.0</td>\n",
       "      <td>19152.10</td>\n",
       "      <td>180237.0</td>\n",
       "      <td>77087.8</td>\n",
       "      <td>71378.9</td>\n",
       "      <td>476101.0</td>\n",
       "      <td>38553.1</td>\n",
       "      <td>22682.9</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>27079_0</td>\n",
       "      <td>27079</td>\n",
       "      <td>0</td>\n",
       "      <td>10500.20</td>\n",
       "      <td>657698.0</td>\n",
       "      <td>21278.9</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>14027.50</td>\n",
       "      <td>3523.85</td>\n",
       "      <td>105131.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3051810.0</td>\n",
       "      <td>106767.00</td>\n",
       "      <td>1163020.0</td>\n",
       "      <td>76054.5</td>\n",
       "      <td>197783.0</td>\n",
       "      <td>668993.0</td>\n",
       "      <td>47629.7</td>\n",
       "      <td>18425.9</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>40022_12</td>\n",
       "      <td>40022</td>\n",
       "      <td>12</td>\n",
       "      <td>9226.03</td>\n",
       "      <td>449103.0</td>\n",
       "      <td>25640.5</td>\n",
       "      <td>21990.3</td>\n",
       "      <td>23360.20</td>\n",
       "      <td>2945.62</td>\n",
       "      <td>112760.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2948620.0</td>\n",
       "      <td>58186.60</td>\n",
       "      <td>350407.0</td>\n",
       "      <td>96296.7</td>\n",
       "      <td>82804.8</td>\n",
       "      <td>377456.0</td>\n",
       "      <td>47010.1</td>\n",
       "      <td>13725.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1068 rows Ã— 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      visit_id  patient_id  visit_month    O00391    O00533   O00584   O14498  \\\n",
       "0     64674_84       64674           84      0.00  190487.0  24907.9  18543.1   \n",
       "1      57507_0       57507            0   8283.24  482542.0  36667.9  30565.5   \n",
       "2     64674_12       64674           12      0.00  188974.0  18100.6  16229.9   \n",
       "3     51708_48       51708           48      0.00  359661.0  26235.8  26673.4   \n",
       "4      20352_0       20352            0  11209.50  640924.0  29576.7  29438.1   \n",
       "...        ...         ...          ...       ...       ...      ...      ...   \n",
       "1063  30894_60       30894           60   8024.28  347378.0  28456.3  27444.6   \n",
       "1064  14035_60       14035           60   7231.95  423538.0  26651.3  17903.3   \n",
       "1065  59550_60       59550           60  11212.70  451740.0  25389.2  17247.7   \n",
       "1066   27079_0       27079            0  10500.20  657698.0  21278.9  25957.3   \n",
       "1067  40022_12       40022           12   9226.03  449103.0  25640.5  21990.3   \n",
       "\n",
       "        O14773   O14791    O15240  ...  YVGGQEHFAHLLILR_P02763  \\\n",
       "0     10124.90  2308.71   62095.4  ...               4901220.0   \n",
       "1     26054.90  1463.14  147160.0  ...               2761210.0   \n",
       "2      4728.27  2731.76   26262.9  ...               5373440.0   \n",
       "3     15429.30  3528.49   87260.7  ...                     0.0   \n",
       "4     15884.60  4535.01  206610.0  ...               5593620.0   \n",
       "...        ...      ...       ...  ...                     ...   \n",
       "1063   5079.26  2335.54  109329.0  ...                     0.0   \n",
       "1064  13334.90  1625.71  129916.0  ...               2099330.0   \n",
       "1065   9819.39  3405.69  204601.0  ...               4659100.0   \n",
       "1066  14027.50  3523.85  105131.0  ...               3051810.0   \n",
       "1067  23360.20  2945.62  112760.0  ...               2948620.0   \n",
       "\n",
       "      YVM(UniMod_35)LPVADQDQC(UniMod_4)IR_P00738  \\\n",
       "0                                       40325.90   \n",
       "1                                       32719.80   \n",
       "2                                       56942.20   \n",
       "3                                        2673.08   \n",
       "4                                      152364.00   \n",
       "...                                          ...   \n",
       "1063                                    33420.00   \n",
       "1064                                        0.00   \n",
       "1065                                    19152.10   \n",
       "1066                                   106767.00   \n",
       "1067                                    58186.60   \n",
       "\n",
       "      YVMLPVADQDQC(UniMod_4)IR_P00738  YVNKEIQNAVNGVK_P10909  \\\n",
       "0                            335625.0                49250.4   \n",
       "1                             93142.6                68437.4   \n",
       "2                            400014.0                49278.7   \n",
       "3                            305865.0                70153.4   \n",
       "4                           2258450.0               104239.0   \n",
       "...                               ...                    ...   \n",
       "1063                         269386.0                96326.9   \n",
       "1064                         204434.0                74873.4   \n",
       "1065                         180237.0                77087.8   \n",
       "1066                        1163020.0                76054.5   \n",
       "1067                         350407.0                96296.7   \n",
       "\n",
       "      YWGVASFLQK_P02753  YYC(UniMod_4)FQGNQFLR_P02790  YYTYLIMNK_P01024  \\\n",
       "0               64076.3                      667993.0           38472.5   \n",
       "1              102022.0                      371103.0           30842.2   \n",
       "2              100833.0                      599158.0           50942.2   \n",
       "3              107281.0                       47861.6           39870.2   \n",
       "4              164414.0                      443939.0           63222.0   \n",
       "...                 ...                           ...               ...   \n",
       "1063           131866.0                      545595.0           47572.8   \n",
       "1064           129314.0                      425445.0           43636.3   \n",
       "1065            71378.9                      476101.0           38553.1   \n",
       "1066           197783.0                      668993.0           47629.7   \n",
       "1067            82804.8                      377456.0           47010.1   \n",
       "\n",
       "      YYWGGQYTWDMAK_P02675  kfold  updrs_1  \n",
       "0                  21949.1      0      5.0  \n",
       "1                      0.0      0      1.0  \n",
       "2                  28021.0      0      5.0  \n",
       "3                  32233.2      0      5.0  \n",
       "4                  19664.8      0      0.0  \n",
       "...                    ...    ...      ...  \n",
       "1063               40027.6      4      2.0  \n",
       "1064               26534.8      4      8.0  \n",
       "1065               22682.9      4     10.0  \n",
       "1066               18425.9      4      2.0  \n",
       "1067               13725.7      4      1.0  \n",
       "\n",
       "[1068 rows x 1200 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df_for_visit0(train_df, train_df_dict, 'updrs_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:30:09.338897Z",
     "iopub.status.busy": "2023-04-29T18:30:09.33596Z",
     "iopub.status.idle": "2023-04-29T18:34:12.830252Z",
     "shell.execute_reply": "2023-04-29T18:34:12.828136Z",
     "shell.execute_reply.started": "2023-04-29T18:30:09.338858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE = 37.06, R2 = 0.8898357203783738, MAPE = 564889706069805.2\n",
      "SMAPE = 67.28, R2 = 0.892564040048107, MAPE = 1985421172804167.5\n",
      "SMAPE = 58.7, R2 = 0.8942111317898853, MAPE = 4165020880337368.5\n",
      "SMAPE = 129.42, R2 = 0.8589735911489575, MAPE = 2003349915085670.2\n",
      "updrs_1 6 SMAPE: 36.71\n",
      "updrs_1 12 SMAPE: 33.9\n",
      "updrs_1 24 SMAPE: 35.79\n",
      "updrs_2 6 SMAPE: 22.85\n",
      "updrs_2 12 SMAPE: 67.54\n",
      "updrs_2 24 SMAPE: 70.02\n",
      "updrs_3 6 SMAPE: 21.21\n",
      "updrs_3 12 SMAPE: 47.77\n",
      "updrs_3 24 SMAPE: 51.69\n",
      "updrs_4 6 forecasting model failed!!!!!\n",
      "updrs_4 12 SMAPE: 127.97\n",
      "updrs_4 24 SMAPE: 113.1\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "trained_models_dict, visit0_col_dict = train_rf_model(train_df_dict)\n",
    "    \n",
    "\n",
    "processed_forecast_dict = dict()\n",
    "\n",
    "for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n",
    "    \n",
    "    forecast_data = train_df_dict[updr]\n",
    "    processed_forecast_dict[updr] = preprocess_forecast_train_df(forecast_data, updr)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "forecast_col_dict = {'updrs_1':{6:_, 12:_, 24:_}, 'updrs_2':{6:_, 12:_, 24:_}, 'updrs_3':{6:_, 12:_, 24:_}, 'updrs_4':{6:_, 12:_, 24:_}}\n",
    "\n",
    "model_1_6, model_1_12, model_1_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n",
    "model_2_6, model_2_12, model_2_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n",
    "model_3_6, model_3_12, model_3_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n",
    "model_4_6, model_4_12, model_4_24 = RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42), RandomForestRegressor(random_state=42)\n",
    "\n",
    "# store the instantiated models\n",
    "forecast_dict = {'updrs_1':{6:model_1_6, 12:model_1_12, 24:model_1_24},\n",
    "                 'updrs_2':{6:model_2_6, 12:model_2_12, 24:model_2_24},\n",
    "                 'updrs_3':{6:model_3_6, 12:model_3_12, 24:model_3_24},\n",
    "                 'updrs_4':{6:model_4_6, 12:model_4_12, 24:model_4_24}}\n",
    "\n",
    "\n",
    "for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n",
    "    for month_diff in [6, 12, 24]:\n",
    "        \n",
    "        try:\n",
    "            forecast_model, forecast_cols = train_forecast(forecast_dict[updr][month_diff], processed_forecast_dict, updr, month_diff)\n",
    "            forecast_dict[updr][month_diff] = forecast_model\n",
    "            forecast_col_dict[updr][month_diff] = forecast_cols\n",
    "        except:\n",
    "            print(f'{updr} {month_diff} forecasting model failed!!!!!')\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:34:12.834232Z",
     "iopub.status.busy": "2023-04-29T18:34:12.833906Z",
     "iopub.status.idle": "2023-04-29T18:34:12.841389Z",
     "shell.execute_reply": "2023-04-29T18:34:12.840228Z",
     "shell.execute_reply.started": "2023-04-29T18:34:12.834202Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_test_cols(test_df, pred_cols):\n",
    "    '''\n",
    "        Takes in the prediction columns and the test dataframe\n",
    "        Returns the dataframe with all of the necessary columns for prediction\n",
    "    '''\n",
    "    # get the missing columns need for prediction\n",
    "    missing_cols_from_test = [col for col in pred_cols if col not in test_df.columns]\n",
    "\n",
    "    # create a dataframe with those columns\n",
    "    missing_cols_df = pd.DataFrame(columns = missing_cols_from_test)\n",
    "\n",
    "    # concat these columns to the test_df\n",
    "    test_df = pd.concat([test_df, missing_cols_df], axis=1)\n",
    "\n",
    "    # fill the na with 0\n",
    "    test_df = test_df.fillna(0)\n",
    "\n",
    "    return test_df[pred_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:38:10.117285Z",
     "iopub.status.busy": "2023-04-29T18:38:10.116813Z",
     "iopub.status.idle": "2023-04-29T18:38:10.148717Z",
     "shell.execute_reply": "2023-04-29T18:38:10.146615Z",
     "shell.execute_reply.started": "2023-04-29T18:38:10.117245Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_submission(test_df, test_prot_df, test_pep_df, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict):\n",
    "\n",
    "    '''\n",
    "    Need to input the following variables:\n",
    "\n",
    "    test_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test.csv')\n",
    "    test_prot_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_proteins.csv')\n",
    "    test_pep_df = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_peptides.csv')\n",
    "    visit0_col_dict\n",
    "    trained_models_dict\n",
    "    forecast_col_dict\n",
    "    forecast_dict\n",
    "    '''\n",
    "    test_preprocessed_df = preprocess_test_df(test_df, test_prot_df, test_pep_df)\n",
    "\n",
    "\n",
    "\n",
    "    visit0_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    # for visit 0\n",
    "    for updr in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n",
    "    \n",
    "        # predict the 0 visit first\n",
    "        md_df, row_id = prepare_model_df(test_preprocessed_df, updr, visit0_col_dict[updr], visit_month=0)\n",
    "        md_df = fill_test_cols(md_df, visit0_col_dict[updr])\n",
    "        trained_model = trained_models_dict[updr]\n",
    "        preds = trained_model.predict(md_df.values)\n",
    "        row_id[f'{updr}'] = preds\n",
    "        # use value 0 for the updrs_4\n",
    "        if updr == 'updrs_4':\n",
    "            row_id['updrs_4'] = 0\n",
    "        temp_df = pd.concat([row_id, md_df], axis=1)\n",
    "        visit0_df = pd.concat([visit0_df, temp_df])\n",
    "\n",
    "        for month in [6, 12, 24]:\n",
    "            if updr == 'updrs_4' and month == 6:\n",
    "                # split the difference between 0 and 12\n",
    "                forecast_cols = forecast_col_dict[updr][12]\n",
    "                forecast_df = visit0_df.dropna(subset=[updr])\n",
    "                forecast_id = forecast_df['row_id']\n",
    "                forecast_df = fill_test_cols(forecast_df, forecast_cols)\n",
    "                \n",
    "    \n",
    "                # get the forecast model\n",
    "                forecast_model = forecast_dict[updr][12]\n",
    "                preds = forecast_model.predict(forecast_df.values)\n",
    "                visit0_preds = forecast_df['updrs_4']\n",
    "                impute_preds = (preds + visit0_preds) / 2\n",
    "                # use 0 value for updrs_4 instead of prediction\n",
    "                forecast_df[f'{updr}_{month}'] = 0\n",
    "                visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n",
    "                \n",
    "            elif updr == 'updrs_4':\n",
    "                forecast_cols = forecast_col_dict[updr][month]\n",
    "                forecast_df = visit0_df.dropna(subset=[updr])\n",
    "                forecast_id = forecast_df['row_id']\n",
    "                forecast_df = fill_test_cols(forecast_df, forecast_cols)\n",
    "    \n",
    "                # get the forecast model\n",
    "                forecast_model = forecast_dict[updr][month]\n",
    "                preds = forecast_model.predict(forecast_df.values)\n",
    "                # use 0 value for updrs_4 instead of the prediction\n",
    "                forecast_df[f'{updr}_{month}'] = 0\n",
    "                visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n",
    "            \n",
    "            else:\n",
    "                # predict the 6, 12, and 24 later visits\n",
    "                forecast_cols = forecast_col_dict[updr][month]\n",
    "                forecast_df = visit0_df.dropna(subset=[updr])\n",
    "                forecast_id = forecast_df['row_id']\n",
    "                forecast_df = fill_test_cols(forecast_df, forecast_cols)\n",
    "    \n",
    "                # get the forecast model\n",
    "                forecast_model = forecast_dict[updr][month]\n",
    "                preds = forecast_model.predict(forecast_df.values)\n",
    "                forecast_df[f'{updr}_{month}'] = preds\n",
    "                visit0_df = visit0_df.join(forecast_df[f'{updr}_{month}'])\n",
    "            \n",
    "        final_df = pd.concat([final_df, visit0_df])\n",
    "        final_df = final_df.drop_duplicates()\n",
    "            \n",
    "    pred_df = final_df[[col for col in final_df.columns if col == 'row_id' or col[:5] == 'updrs']]\n",
    "\n",
    "    melted_df = pd.melt(pred_df, id_vars=['row_id'], value_vars=pred_df.columns[1:])\n",
    "    melted_df = melted_df.dropna()\n",
    "\n",
    "    for i, row in melted_df.iterrows():\n",
    "        if row['variable'] in ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']:\n",
    "            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_0_months'\n",
    "        elif row['variable'] in ['updrs_1_6', 'updrs_2_6', 'updrs_3_6', 'updrs_4_6']:\n",
    "            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_6_months'\n",
    "        elif row['variable'] in ['updrs_1_12', 'updrs_2_12', 'updrs_3_12', 'updrs_4_12']:\n",
    "            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_12_months'\n",
    "        else:\n",
    "            melted_df.loc[i, 'row_id'] = row['row_id'] + '_plus_24_months'\n",
    "        \n",
    "    melted_df = melted_df.rename(columns={'value':'rating'}).drop(columns=['variable'])\n",
    "    result = melted_df.reset_index(drop=True)\n",
    "    result = result.rename(columns={'row_id':'prediction_id'})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:38:10.4493Z",
     "iopub.status.busy": "2023-04-29T18:38:10.44887Z",
     "iopub.status.idle": "2023-04-29T18:38:10.471742Z",
     "shell.execute_reply": "2023-04-29T18:38:10.470089Z",
     "shell.execute_reply.started": "2023-04-29T18:38:10.44926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>group_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3342_0_updrs_1_plus_0_months</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3342_0_updrs_1_plus_6_months</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3342_0_updrs_1_plus_12_months</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3342_0_updrs_1_plus_24_months</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3342_0_updrs_2_plus_0_months</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>50423_6_updrs_3_plus_24_months</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50423_6_updrs_4_plus_0_months</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>50423_6_updrs_4_plus_6_months</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>50423_6_updrs_4_plus_12_months</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>50423_6_updrs_4_plus_24_months</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     prediction_id  rating  group_key\n",
       "0     3342_0_updrs_1_plus_0_months       0          0\n",
       "1     3342_0_updrs_1_plus_6_months       0          0\n",
       "2    3342_0_updrs_1_plus_12_months       0          0\n",
       "3    3342_0_updrs_1_plus_24_months       0          0\n",
       "4     3342_0_updrs_2_plus_0_months       0          0\n",
       "..                             ...     ...        ...\n",
       "59  50423_6_updrs_3_plus_24_months       0          6\n",
       "60   50423_6_updrs_4_plus_0_months       0          6\n",
       "61   50423_6_updrs_4_plus_6_months       0          6\n",
       "62  50423_6_updrs_4_plus_12_months       0          6\n",
       "63  50423_6_updrs_4_plus_24_months       0          6\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('/kaggle/input/amp-pd/example_test_files/sample_submission.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:38:11.184132Z",
     "iopub.status.busy": "2023-04-29T18:38:11.183782Z",
     "iopub.status.idle": "2023-04-29T18:38:12.594593Z",
     "shell.execute_reply": "2023-04-29T18:38:12.592704Z",
     "shell.execute_reply.started": "2023-04-29T18:38:11.184102Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test.csv')\n",
    "test_proteins = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_proteins.csv')\n",
    "test_peptides = pd.read_csv('/kaggle/input/amp-pd/example_test_files/test_peptides.csv')\n",
    "result = create_submission(test, test_proteins, test_peptides, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:38:12.601937Z",
     "iopub.status.busy": "2023-04-29T18:38:12.600079Z",
     "iopub.status.idle": "2023-04-29T18:38:12.626818Z",
     "shell.execute_reply": "2023-04-29T18:38:12.625935Z",
     "shell.execute_reply.started": "2023-04-29T18:38:12.601891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3342_0_updrs_1_plus_0_months</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3342_0_updrs_1_plus_12_months</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3342_0_updrs_1_plus_24_months</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3342_0_updrs_1_plus_6_months</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3342_0_updrs_2_plus_0_months</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3342_0_updrs_2_plus_12_months</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3342_0_updrs_2_plus_24_months</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3342_0_updrs_2_plus_6_months</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3342_0_updrs_3_plus_0_months</td>\n",
       "      <td>19.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3342_0_updrs_3_plus_12_months</td>\n",
       "      <td>18.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3342_0_updrs_3_plus_24_months</td>\n",
       "      <td>20.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3342_0_updrs_3_plus_6_months</td>\n",
       "      <td>19.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3342_0_updrs_4_plus_0_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3342_0_updrs_4_plus_12_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3342_0_updrs_4_plus_24_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3342_0_updrs_4_plus_6_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3342_6_updrs_1_plus_0_months</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3342_6_updrs_1_plus_12_months</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3342_6_updrs_1_plus_24_months</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3342_6_updrs_1_plus_6_months</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3342_6_updrs_2_plus_0_months</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3342_6_updrs_2_plus_12_months</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3342_6_updrs_2_plus_24_months</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3342_6_updrs_2_plus_6_months</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3342_6_updrs_3_plus_0_months</td>\n",
       "      <td>19.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3342_6_updrs_3_plus_12_months</td>\n",
       "      <td>18.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3342_6_updrs_3_plus_24_months</td>\n",
       "      <td>20.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3342_6_updrs_3_plus_6_months</td>\n",
       "      <td>19.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3342_6_updrs_4_plus_0_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3342_6_updrs_4_plus_12_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3342_6_updrs_4_plus_24_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3342_6_updrs_4_plus_6_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50423_0_updrs_1_plus_0_months</td>\n",
       "      <td>8.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50423_0_updrs_1_plus_12_months</td>\n",
       "      <td>7.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50423_0_updrs_1_plus_24_months</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50423_0_updrs_1_plus_6_months</td>\n",
       "      <td>10.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50423_0_updrs_2_plus_0_months</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50423_0_updrs_2_plus_12_months</td>\n",
       "      <td>9.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50423_0_updrs_2_plus_24_months</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50423_0_updrs_2_plus_6_months</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50423_0_updrs_3_plus_0_months</td>\n",
       "      <td>22.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50423_0_updrs_3_plus_12_months</td>\n",
       "      <td>23.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>50423_0_updrs_3_plus_24_months</td>\n",
       "      <td>23.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>50423_0_updrs_3_plus_6_months</td>\n",
       "      <td>31.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>50423_0_updrs_4_plus_0_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>50423_0_updrs_4_plus_12_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>50423_0_updrs_4_plus_24_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>50423_0_updrs_4_plus_6_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50423_6_updrs_1_plus_0_months</td>\n",
       "      <td>8.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50423_6_updrs_1_plus_12_months</td>\n",
       "      <td>7.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50423_6_updrs_1_plus_24_months</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50423_6_updrs_1_plus_6_months</td>\n",
       "      <td>10.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50423_6_updrs_2_plus_0_months</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50423_6_updrs_2_plus_12_months</td>\n",
       "      <td>9.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>50423_6_updrs_2_plus_24_months</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>50423_6_updrs_2_plus_6_months</td>\n",
       "      <td>8.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>50423_6_updrs_3_plus_0_months</td>\n",
       "      <td>22.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>50423_6_updrs_3_plus_12_months</td>\n",
       "      <td>23.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>50423_6_updrs_3_plus_24_months</td>\n",
       "      <td>23.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>50423_6_updrs_3_plus_6_months</td>\n",
       "      <td>31.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>50423_6_updrs_4_plus_0_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>50423_6_updrs_4_plus_12_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>50423_6_updrs_4_plus_24_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>50423_6_updrs_4_plus_6_months</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     prediction_id  rating\n",
       "2     3342_0_updrs_1_plus_0_months    5.14\n",
       "10   3342_0_updrs_1_plus_12_months    4.84\n",
       "14   3342_0_updrs_1_plus_24_months    6.42\n",
       "6     3342_0_updrs_1_plus_6_months    6.33\n",
       "18    3342_0_updrs_2_plus_0_months    4.39\n",
       "26   3342_0_updrs_2_plus_12_months    6.89\n",
       "30   3342_0_updrs_2_plus_24_months    6.20\n",
       "22    3342_0_updrs_2_plus_6_months    5.64\n",
       "34    3342_0_updrs_3_plus_0_months   19.07\n",
       "42   3342_0_updrs_3_plus_12_months   18.93\n",
       "46   3342_0_updrs_3_plus_24_months   20.27\n",
       "38    3342_0_updrs_3_plus_6_months   19.05\n",
       "50    3342_0_updrs_4_plus_0_months    0.00\n",
       "58   3342_0_updrs_4_plus_12_months    0.00\n",
       "62   3342_0_updrs_4_plus_24_months    0.00\n",
       "54    3342_0_updrs_4_plus_6_months    0.00\n",
       "1     3342_6_updrs_1_plus_0_months    5.14\n",
       "9    3342_6_updrs_1_plus_12_months    4.84\n",
       "13   3342_6_updrs_1_plus_24_months    6.42\n",
       "5     3342_6_updrs_1_plus_6_months    6.33\n",
       "17    3342_6_updrs_2_plus_0_months    4.39\n",
       "25   3342_6_updrs_2_plus_12_months    6.89\n",
       "29   3342_6_updrs_2_plus_24_months    6.20\n",
       "21    3342_6_updrs_2_plus_6_months    5.64\n",
       "32    3342_6_updrs_3_plus_0_months   19.07\n",
       "40   3342_6_updrs_3_plus_12_months   18.93\n",
       "44   3342_6_updrs_3_plus_24_months   20.27\n",
       "36    3342_6_updrs_3_plus_6_months   19.05\n",
       "49    3342_6_updrs_4_plus_0_months    0.00\n",
       "57   3342_6_updrs_4_plus_12_months    0.00\n",
       "61   3342_6_updrs_4_plus_24_months    0.00\n",
       "53    3342_6_updrs_4_plus_6_months    0.00\n",
       "0    50423_0_updrs_1_plus_0_months    8.03\n",
       "8   50423_0_updrs_1_plus_12_months    7.79\n",
       "12  50423_0_updrs_1_plus_24_months    8.80\n",
       "4    50423_0_updrs_1_plus_6_months   10.07\n",
       "16   50423_0_updrs_2_plus_0_months    7.44\n",
       "24  50423_0_updrs_2_plus_12_months    9.83\n",
       "28  50423_0_updrs_2_plus_24_months    9.67\n",
       "20   50423_0_updrs_2_plus_6_months    8.40\n",
       "33   50423_0_updrs_3_plus_0_months   22.48\n",
       "41  50423_0_updrs_3_plus_12_months   23.40\n",
       "45  50423_0_updrs_3_plus_24_months   23.66\n",
       "37   50423_0_updrs_3_plus_6_months   31.50\n",
       "48   50423_0_updrs_4_plus_0_months    0.00\n",
       "56  50423_0_updrs_4_plus_12_months    0.00\n",
       "60  50423_0_updrs_4_plus_24_months    0.00\n",
       "52   50423_0_updrs_4_plus_6_months    0.00\n",
       "3    50423_6_updrs_1_plus_0_months    8.03\n",
       "11  50423_6_updrs_1_plus_12_months    7.79\n",
       "15  50423_6_updrs_1_plus_24_months    8.80\n",
       "7    50423_6_updrs_1_plus_6_months   10.07\n",
       "19   50423_6_updrs_2_plus_0_months    7.44\n",
       "27  50423_6_updrs_2_plus_12_months    9.83\n",
       "31  50423_6_updrs_2_plus_24_months    9.67\n",
       "23   50423_6_updrs_2_plus_6_months    8.40\n",
       "35   50423_6_updrs_3_plus_0_months   22.48\n",
       "43  50423_6_updrs_3_plus_12_months   23.40\n",
       "47  50423_6_updrs_3_plus_24_months   23.66\n",
       "39   50423_6_updrs_3_plus_6_months   31.50\n",
       "51   50423_6_updrs_4_plus_0_months    0.00\n",
       "59  50423_6_updrs_4_plus_12_months    0.00\n",
       "63  50423_6_updrs_4_plus_24_months    0.00\n",
       "55   50423_6_updrs_4_plus_6_months    0.00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "result.sort_values(by='prediction_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Through the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:38:13.802365Z",
     "iopub.status.busy": "2023-04-29T18:38:13.801267Z",
     "iopub.status.idle": "2023-04-29T18:38:13.808151Z",
     "shell.execute_reply": "2023-04-29T18:38:13.806856Z",
     "shell.execute_reply.started": "2023-04-29T18:38:13.802293Z"
    }
   },
   "outputs": [],
   "source": [
    "env = amp_pd_peptide.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T18:38:15.26316Z",
     "iopub.status.busy": "2023-04-29T18:38:15.262739Z",
     "iopub.status.idle": "2023-04-29T18:38:17.919652Z",
     "shell.execute_reply": "2023-04-29T18:38:17.918644Z",
     "shell.execute_reply.started": "2023-04-29T18:38:15.263126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n",
    "        \n",
    "    result = create_submission(test, test_proteins, test_peptides, visit0_col_dict, trained_models_dict, forecast_col_dict, forecast_dict)\n",
    "\n",
    "    env.predict(result)   # register your predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
